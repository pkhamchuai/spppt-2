{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 360 training images and 40 testing images\n",
      "Location of the images: Dataset/synthetic_shape_dataset\n",
      "Saving affine parameters to Dataset/synthetic_shape_dataset/dataset_shape_synth_train.csv and Dataset/synthetic_shape_dataset/dataset_shape_synth_test.csv\n",
      "Done!\n",
      "MAE point location error: 0.4179319398359124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import shutil\n",
    "import csv\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from utils.utils0 import tensor_affine_transform, transform_to_displacement_field\n",
    "from utils.utils1 import transform_points_DVF\n",
    "from utils.SuperPoint import SuperPointFrontend, PointTracker\n",
    "superpoint = SuperPointFrontend('utils/superpoint_v1.pth', nms_dist=4,\n",
    "                          conf_thresh=0.015, nn_thresh=0.7, cuda=True)\n",
    "\n",
    "# Define parameters\n",
    "image_size = (256, 256)  # Size of the images\n",
    "num_samples = 200  # Number of samples for each shape\n",
    "max_translation = 20  # Maximum translation in pixels\n",
    "max_rotation = 10  # Maximum rotation in degrees\n",
    "max_shear = 5  # Maximum shear in degrees\n",
    "max_scale = 1.1  # Maximum scale factor\n",
    "\n",
    "# Create a function to generate star images\n",
    "def generate_star_images(num_samples, output_dir=\"Dataset/synthetic_shape_dataset\", num_images=1):\n",
    "    # delete all files and subdirectories in the output directory\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Create a csv file to store the affine parameters (training and validation sets)\n",
    "    affine_parameters_path_train = os.path.join('Dataset', \"dataset_shape_synth_train.csv\")\n",
    "    with open(affine_parameters_path_train, \"w\", newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"source\", \"target\", \"M00\", \"M01\", \"M02\", \"M10\", \"M11\", \"M12\"])\n",
    "    affine_parameters_path_test = os.path.join('Dataset', \"dataset_shape_synth_test.csv\")\n",
    "    with open(affine_parameters_path_test, \"w\", newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"source\", \"target\", \"M00\", \"M01\", \"M02\", \"M10\", \"M11\", \"M12\"])\n",
    "\n",
    "    # save 10% of the images for testing\n",
    "    num_test = int(num_samples * 0.1)\n",
    "    num_train = num_samples - num_test\n",
    "    print(f\"Generating {num_images*num_train} training images and {num_images*num_test} testing images\")\n",
    "    print(f\"Location of the images: {output_dir}\")\n",
    "    print(f\"Saving affine parameters to {affine_parameters_path_train} and {affine_parameters_path_test}\")\n",
    "\n",
    "    # create a list to store different point locations\n",
    "    points_list = []\n",
    "\n",
    "    # Generate images\n",
    "    for i in range(num_samples):\n",
    "        \n",
    "        # Create a fixed-size image\n",
    "        image = Image.new(\"L\", image_size, 0)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        \n",
    "        # Draw a star centered in the image\n",
    "        center = (image_size[0] // 2, image_size[1] // 2)\n",
    "        size = np.random.randint(50, min(image_size) // 2)\n",
    "        points = []\n",
    "        for _ in range(10):\n",
    "            angle = np.random.uniform(0, 2 * np.pi)\n",
    "            x = int(center[0] + size * np.cos(angle))\n",
    "            y = int(center[1] + size * np.sin(angle))\n",
    "            points.append((x, y))\n",
    "        draw.polygon(points, fill=np.random.randint(100, 256))\n",
    "\n",
    "        # Save original image\n",
    "        original_image_path = os.path.join(output_dir, f\"star_{i}_original.png\")\n",
    "        #cv2.imwrite(original_image_path, image)\n",
    "        image.save(original_image_path)\n",
    "\n",
    "        for j in range(num_images):\n",
    "            # random (2x3) affine transformation matrix\n",
    "            #M = np.array([[1.0, 0.0, np.random()], [0.0, 1.0, 0.0]])\n",
    "            rand_range = 0.2\n",
    "            test_random = np.random.uniform(-rand_range, rand_range, 2)\n",
    "            M = np.array([[1.0, 0.0, test_random[0]], [0.0, 1.0, test_random[1]]])\n",
    "\n",
    "            image = np.array(image)\n",
    "            img_transformed = tensor_affine_transform(torch.tensor(image).unsqueeze(0).unsqueeze(0).float(), \n",
    "                                                      torch.tensor(M).unsqueeze(0).float())\n",
    "            img_transformed = img_transformed.squeeze(0).squeeze(0).numpy()\n",
    "\n",
    "            # TODO: save heatmaps for other version of network\n",
    "            points1, desc1, heatmap1 = superpoint(image.astype(np.float32)/255)\n",
    "            points2, desc2, heatmap2 = superpoint(np.array(img_transformed).astype(np.float32)/255)\n",
    "\n",
    "            tracker = PointTracker(5, nn_thresh=0.7)\n",
    "            matches = tracker.nn_match_two_way(desc1, desc2, nn_thresh=0.7)\n",
    "\n",
    "            matches1 = points1[:2, matches[0, :].astype(int)]\n",
    "            # matches1 = matches1.T[None, :, :]\n",
    "            matches2 = points2[:2, matches[1, :].astype(int)]\n",
    "            \n",
    "            # add noise to the transformed image and save it\n",
    "            img_transformed = img_transformed + np.random.randint(-10, 10, size=img_transformed.shape)\n",
    "            transformed_image_path = os.path.join(output_dir, f\"star_{i}_transformed_{j}.png\")\n",
    "            cv2.imwrite(transformed_image_path, np.array(img_transformed))\n",
    "\n",
    "            # transform the points using the displacement field\n",
    "            # print(torch.tensor(M)[None, :, :].shape, torch.tensor(image)[None, None, :, :].shape)\n",
    "            matches1_transformed_DVF = transform_points_DVF(matches1.copy(), \n",
    "                torch.tensor(M).view(1, 2, 3), torch.tensor(image)[None, None, :, :])\n",
    "            # print(f'Img {i}, diff: {matches1_transformed_DVF[:, 0] - matches2[:, 0]}')\n",
    "            points_list.append(matches1_transformed_DVF[:, 0] - matches2[:, 0])\n",
    "\n",
    "            # Save affine parameters to a csv file (one line per image pair)\n",
    "            if i < num_test:\n",
    "                with open(affine_parameters_path_test, \"a\", newline='') as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerow([original_image_path, transformed_image_path, \n",
    "                                     M[0, 0], M[0, 1], M[0, 2], M[1, 0], M[1, 1], M[1, 2]])\n",
    "            else:\n",
    "                with open(affine_parameters_path_train, \"a\", newline='') as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerow([original_image_path, transformed_image_path, \n",
    "                                     M[0, 0], M[0, 1], M[0, 2], M[1, 0], M[1, 1], M[1, 2]])\n",
    "    print(\"Done!\")\n",
    "    print('MAE point location error:', np.mean(np.abs(np.array(points_list))))\n",
    "    print()\n",
    "\n",
    "# Generate star images\n",
    "output_dir = \"Dataset/synthetic_shape_dataset\"  # Output directory\n",
    "generate_star_images(num_samples, output_dir=output_dir, num_images=2)\n",
    "\n",
    "# Generate star images with 2 transformations\n",
    "output_dir = \"Dataset/synthetic_shape_dataset_multiple\"  # Output directory\n",
    "# generate_star_images(num_samples, output_dir=output_dir, num_images=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab images in the directory\n",
    "# import glob\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "# import cv2\n",
    "\n",
    "# # grab images in the directory\n",
    "# images = glob.glob('Dataset/synthetic_shape_dataset/*.png')\n",
    "# len(images)\n",
    "\n",
    "# # sort images\n",
    "# images.sort()\n",
    "# for i in range(len(images)):\n",
    "#     print(images[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SIFT to detect and extract features from the image \n",
    "# and plot the images in pairs with the keypoints overlaid\n",
    "# sift = cv2.SIFT_create()\n",
    "\n",
    "# for i in range(0, 100, 2):\n",
    "#     fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "#     img1 = cv2.imread(images[i], 0)\n",
    "#     img2 = cv2.imread(images[i+1], 0)\n",
    "#     kp, des = sift.detectAndCompute(img1, None)\n",
    "#     img = cv2.drawKeypoints(img1, kp, None)\n",
    "#     ax[0].imshow(img)\n",
    "#     ax[0].axis('off')\n",
    "#     ax[0].set_title(f'#{int(i/2+1)} Original Image')\n",
    "\n",
    "#     kp, des = sift.detectAndCompute(img2, None)\n",
    "#     img = cv2.drawKeypoints(img2, kp, None)\n",
    "#     ax[1].imshow(img)\n",
    "#     ax[1].axis('off')\n",
    "#     ax[1].set_title(f'Transformed Image')\n",
    "#     os.makedirs('Dataset/synthetic_shape_dataset/plot', exist_ok=True)\n",
    "#     plt.savefig(f'Dataset/synthetic_shape_dataset/plot/{int(i/2+1)}.png')\n",
    "#     plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spppt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
