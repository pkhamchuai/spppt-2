{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 7391080293760653151\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# from skimage.metrics import structural_similarity as ssim\n",
    "# from skimage.measure import ransac\n",
    "# from skimage.transform import FundamentalMatrixTransform, AffineTransform\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "# from torchvision import transforms\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils import data\n",
    "# from torchsummary import summary\n",
    "# from pytorch_model_summary import summary\n",
    "\n",
    "torch.manual_seed(9793047918980052389)\n",
    "print('Seed:', torch.seed())\n",
    "\n",
    "from utils.utils0 import *\n",
    "from utils.utils1 import *\n",
    "from utils.utils1 import ModelParams, print_summary\n",
    "from utils import test\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')\n",
    "\n",
    "# Stub to warn about opencv version.\n",
    "if int(cv2.__version__[0]) < 3: # pragma: no cover\n",
    "  print('Warning: OpenCV 3 is not installed')\n",
    "\n",
    "image_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from utils.SuperPoint import SuperPointFrontend\n",
    "# from utils.utils1 import transform_points_DVF\n",
    "def test(model_name, models, model_params, timestamp):\n",
    "    # model_name: name of the model\n",
    "    # model: model to be tested\n",
    "    # model_params: model parameters\n",
    "    # timestamp: timestamp of the model\n",
    "    print('Test function input:', model_name, models, model_params, timestamp)\n",
    "\n",
    "    test_dataset = datagen(model_params.dataset, False, model_params.sup)\n",
    "\n",
    "    model = [0]*len(models)\n",
    "    # load the models one-by-one\n",
    "    for i in range(len(models)):\n",
    "        # if model is a string, load the model\n",
    "        # if model is a loaded model, use the model\n",
    "        if isinstance(models[i], str):\n",
    "            print(f\"\\nLoading model: {models[i]}\")\n",
    "            model[i] = model_loader(model_name, model_params)\n",
    "            buffer = io.BytesIO()\n",
    "            torch.save(model[i].state_dict(), buffer)\n",
    "            buffer.seek(0)\n",
    "            model[i].load_state_dict(torch.load(models[i]))\n",
    "            # print(f'Loaded model from {model[i]}')\n",
    "        elif isinstance(models[i], nn.Module):\n",
    "            print(f'Using model {model_name}')\n",
    "            model[i] = models[i]\n",
    "\n",
    "        # Set model to training mode\n",
    "        model[i].eval()\n",
    "\n",
    "    # Create output directory\n",
    "    output_dir = f\"output/{model_name}_{model_params.get_model_code()}_{timestamp}_ensemble_test\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Validate model\n",
    "    # validation_loss = 0.0\n",
    "\n",
    "    metrics = []\n",
    "    # create a csv file to store the metrics\n",
    "    csv_file = f\"{output_dir}/metrics.csv\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        testbar = tqdm(test_dataset, desc=f'Testing:')\n",
    "        for i, data in enumerate(testbar, 0):\n",
    "            # Get images and affine parameters\n",
    "            source_image, target_image, affine_params_true, points1, points2, points1_2_true = data\n",
    "\n",
    "            source_image = source_image.requires_grad_(True).to(device)\n",
    "            target_image = target_image.requires_grad_(True).to(device)\n",
    "            # add gradient to the matches\n",
    "            points1 = points1.requires_grad_(True).to(device)\n",
    "            points2 = points2.requires_grad_(True).to(device)\n",
    "\n",
    "            # TODO: how to repeat the test?\n",
    "            # 1. until the affine parameters are not change anymore\n",
    "            # 2. until the mse is not change anymore\n",
    "            # 3. until the mse is not change anymore and the affine parameters are not change anymore\n",
    "\n",
    "            # use for loop with a large number of iterations \n",
    "            # check TRE of points1 and points2\n",
    "            # if TRE grows larger than the last iteration, stop the loop\n",
    "            TRE_last = np.inf\n",
    "            MSE_last = np.inf\n",
    "            mse12 = 0\n",
    "            tre12 = 0\n",
    "\n",
    "            mse_before_first, tre_before_first, mse12_image_before_first, \\\n",
    "                ssim12_image_before_first = 0, 0, 0, 0\n",
    "            mse_before, tre_before, mse12_image, ssim12_image = 0, 0, 0, 0\n",
    "\n",
    "            rep = 2\n",
    "            votes = [np.inf] * rep  # Initialize a list to store the votes for each model\n",
    "            mse_list = [np.inf] * 5\n",
    "            tre_list = [np.inf] * 5\n",
    "            no_improve = 0\n",
    "\n",
    "            for j in range(rep):\n",
    "                for k in range(len(models)):\n",
    "                    # Forward + backward + optimize\n",
    "                    outputs = model[k](source_image, target_image, points1)\n",
    "                    transformed_source_affine = outputs[0]\n",
    "                    affine_params_predicted = outputs[1]\n",
    "                    points1_2_predicted = outputs[2]\n",
    "\n",
    "                    # if i is an odd number\n",
    "                    if i % 2 == 1 and i < 10 and model_params.plot == 0:\n",
    "                        plot_ = True\n",
    "                    else:\n",
    "                        plot_ = False\n",
    "\n",
    "                    results = DL_affine_plot(f\"test_{i}\", output_dir,\n",
    "                        f\"{i+1}\", f\"rep{j:02d}_{k}\", source_image[0, 0, :, :].cpu().numpy(), \n",
    "                        target_image[0, 0, :, :].cpu().numpy(), \n",
    "                        transformed_source_affine[0, 0, :, :].cpu().numpy(),\n",
    "                        points1[0].cpu().detach().numpy().T, \n",
    "                        points2[0].cpu().detach().numpy().T, \n",
    "                        points1_2_predicted[0].cpu().detach().numpy().T, None, None, \n",
    "                        affine_params_true=affine_params_true,\n",
    "                        affine_params_predict=affine_params_predicted, \n",
    "                        heatmap1=None, heatmap2=None, plot=plot_)\n",
    "\n",
    "                    mse_before = results[1]\n",
    "                    tre_before = results[3]\n",
    "                    mse12_image_before = results[5]\n",
    "                    ssim12_image_before = results[7]\n",
    "\n",
    "                    mse12 = results[2]\n",
    "                    tre12 = results[4]\n",
    "                    mse12_image = results[6]\n",
    "                    ssim12_image = results[8]\n",
    "\n",
    "                    mse_list[k] = mse12\n",
    "                    tre_list[k] = tre12\n",
    "\n",
    "                    if j == 0 and k == 0:\n",
    "                        mse_before_first, tre_before_first, mse12_image_before_first, \\\n",
    "                            ssim12_image_before_first = mse_before, tre_before, mse12_image_before, ssim12_image_before\n",
    "                        # print(mse_before_first, tre_before_first, mse12_image_before_first, ssim12_image_before_first)\n",
    "                \n",
    "                # print(f\"Pair {i}, Rep {j}: {mse_list}, {tre_list}\")\n",
    "                # the lowset mse12 and tre12 and its index\n",
    "                mse12, tre12 = np.min(mse_list), np.min(tre_list)\n",
    "                best_mse = np.argmin([mse_list])  # Find the index of the model with the best results\n",
    "                best_tre = np.argmin([tre_list])  # Find the index of the model with the best results\n",
    "\n",
    "                # print(f\"Pair {i}, Rep {j}: {mse12}, {tre12}, best model: {best_mse}, {best_tre}\")\n",
    "                \n",
    "                # if any element in tre_list is nan, use the model with the lowest mse\n",
    "                if np.isnan(tre12):\n",
    "                    votes[j] = best_tre\n",
    "                else:\n",
    "                    votes[j] = best_mse\n",
    "                    best_tre = best_mse\n",
    "                    tre12 = mse12\n",
    "                    TRE_last = MSE_last\n",
    "\n",
    "                # print(f\"Pair {i}, Rep {j}: {mse12}, {tre12}, best model: {best_tre} {best_mse}\")\n",
    "\n",
    "                outputs = model[best_tre](source_image, target_image, points1)\n",
    "                transformed_source_affine = outputs[0]\n",
    "                affine_params_predicted = outputs[1]\n",
    "                points1_2_predicted = outputs[2]\n",
    "                \n",
    "                if model_params.plot == 1 and i < 50:\n",
    "                    plot_ = True\n",
    "                else:\n",
    "                    plot_ = False\n",
    "\n",
    "                results = DL_affine_plot(f\"test_{i}\", output_dir,\n",
    "                    f\"{i+1}\", f\"rep{j:02d}_{best_tre}\", source_image[0, 0, :, :].cpu().numpy(),\n",
    "                    target_image[0, 0, :, :].cpu().numpy(),\n",
    "                    transformed_source_affine[0, 0, :, :].cpu().numpy(),\n",
    "                    points1[0].cpu().detach().numpy().T,\n",
    "                    points2[0].cpu().detach().numpy().T,\n",
    "                    points1_2_predicted[0].cpu().detach().numpy().T, None, None,\n",
    "                    affine_params_true=affine_params_true,\n",
    "                    affine_params_predict=affine_params_predicted,\n",
    "                    heatmap1=None, heatmap2=None, plot=plot_)\n",
    "                    \n",
    "                # mse_before = results[1]\n",
    "                # tre_before = results[3]\n",
    "                # mse12_image_before = results[5]\n",
    "                # ssim12_image_before = results[7]\n",
    "\n",
    "                mse12 = results[2]\n",
    "                tre12 = results[4]\n",
    "                mse12_image = results[6]\n",
    "                ssim12_image = results[8]\n",
    "\n",
    "                points1 = points1_2_predicted.clone()\n",
    "                source_image = transformed_source_affine.clone()\n",
    "\n",
    "                # apply the best model to this pair\n",
    "                # if tre12 < TRE_last and mse12 < MSE_last:\n",
    "                if tre12 < TRE_last:\n",
    "                    TRE_last = tre12\n",
    "                    MSE_last = mse12\n",
    "                    no_improve -= 1\n",
    "                \n",
    "                else:\n",
    "                    # tre12 = TRE_last\n",
    "                    # mse12 = MSE_last\n",
    "                    no_improve += 1\n",
    "\n",
    "                # if there is no improvement for 2 reps, stop the iteration\n",
    "                if no_improve > 2:\n",
    "                    break\n",
    "\n",
    "            # print(f'\\nEnd register pair {i}')\n",
    "            # print(f'Votes: {votes}\\n')\n",
    "            # break\n",
    "\n",
    "            # append metrics to metrics list\n",
    "            new_entry = [i, mse_before_first, mse12, tre_before_first, tre12, mse12_image_before_first, mse12_image, \\\n",
    "                            ssim12_image_before_first, ssim12_image, np.max(points1_2_predicted.shape), votes]\n",
    "            metrics.append(new_entry)\n",
    "            # print(f\"Pair {i}: {new_entry}\")\n",
    "            # break\n",
    "\n",
    "    with open(csv_file, 'w', newline='') as file:\n",
    "\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"index\", \"mse_before\", \"mse12\", \"tre_before\", \"tre12\", \"mse12_image_before\", \"mse12_image\", \n",
    "                         \"ssim12_image_before\", \"ssim12_image\", \"num_points\", \"votes\"])\n",
    "        for i in range(len(metrics)):\n",
    "            writer.writerow(metrics[i])\n",
    "\n",
    "        # print(metrics[40:42])\n",
    "        \n",
    "        # drop the last column of the array 'metrics'\n",
    "        metrics = [metrics[i][1:-1] for i in range(len(metrics))]\n",
    "        metrics = np.array(metrics)\n",
    "\n",
    "        # print(metrics[40:42])\n",
    "\n",
    "        # metrics = metrics[:, :8]\n",
    "        nan_mask = np.isnan(metrics).any(axis=1)\n",
    "        metrics = metrics[~nan_mask]\n",
    "\n",
    "        print(metrics[40:42])\n",
    "\n",
    "        # avg = [\"average\", np.mean(metrics[:, 1]), np.mean(metrics[:, 2]), np.mean(metrics[:, 3]), np.mean(metrics[:, 4]), \n",
    "        #     np.mean(metrics[:, 5]), np.mean(metrics[:, 6]), np.mean(metrics[:, 7]), np.mean(metrics[:, 8])]\n",
    "        avg = [\"average\", np.mean(metrics[:, 1]), np.mean(metrics[:, 2]), np.mean(metrics[:, 3]), np.mean(metrics[:, 4]), \n",
    "            np.mean(metrics[:, 5]), np.mean(metrics[:, 6]), np.mean(metrics[:, 7]), np.mean(metrics[:, 8])]\n",
    "        std = [\"std\", np.std(metrics[:, 1]), np.std(metrics[:, 2]), np.std(metrics[:, 3]), np.std(metrics[:, 4]),\n",
    "            np.std(metrics[:, 5]), np.std(metrics[:, 6]), np.std(metrics[:, 7]), np.std(metrics[:, 8])]\n",
    "        writer.writerow(avg)\n",
    "        writer.writerow(std)\n",
    "\n",
    "    print(f\"The test results are saved in {csv_file}\")\n",
    "\n",
    "    return csv_file, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:  dataset0_sup0_image1_points0_loss_image0\n",
      "Model code:  00100_0.001_0_1_1\n",
      "Model params:  {'dataset': 0, 'sup': 0, 'image': 1, 'points': 0, 'loss_image_case': 0, 'loss_image': MSELoss(), 'loss_affine': <utils.utils1.loss_affine object at 0x7f0dbc49afb0>, 'learning_rate': 0.001, 'decay_rate': 0.96, 'start_epoch': 0, 'num_epochs': 1, 'batch_size': 1, 'model_name': 'dataset0_sup0_image1_points0_loss_image0'}\n",
      "\n",
      "Model name:  dataset0_sup0_image1_points0_loss_image0\n",
      "Model code:  00100_0.001_0_1_1\n",
      "Dataset used:  Actual eye\n",
      "Supervised or unsupervised model:  Unsupervised\n",
      "Loss image type:  Image used\n",
      "Points used:  Points not used\n",
      "Loss function case:  0\n",
      "Loss function for image:  MSELoss()\n",
      "Loss function for affine:  <utils.utils1.loss_affine object at 0x7f0dbc49afb0>\n",
      "Learning rate:  0.001\n",
      "Decay rate:  0.96\n",
      "Start epoch:  0\n",
      "Number of epochs:  1\n",
      "Batch size:  1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Access the values of the command-line arguments\n",
    "dataset = 0\n",
    "sup = 1\n",
    "image = 1\n",
    "heatmaps = 0\n",
    "loss_image = 0\n",
    "num_epochs = 1\n",
    "learning_rate = 1e-3\n",
    "decay_rate = 0.96\n",
    "model = 'DHR'\n",
    "model_path = None\n",
    "plot = 2\n",
    "\n",
    "# model_path = 'trained_models/' + args.model_path\n",
    "model_path = ['DHR_11100_0.001_0_5_100_20240509-155916.pth', 'DHR_21100_0.001_0_5_100_20240509-160207.pth',\n",
    "            'DHR_31100_0.001_0_10_100_20240508-120807.pth', 'DHR_41100_0.001_0_5_100_20240509-133824.pth',\n",
    "            'DHR_51100_0.001_0_5_100_20240509-140837.pth']\n",
    "# add 'trained_models/' in front of each element of model_path\n",
    "model_path = ['trained_models/' + path for path in model_path]\n",
    "\n",
    "model_params = ModelParams(dataset=dataset, sup=sup, image=image, loss_image=loss_image, \n",
    "                            num_epochs=num_epochs, learning_rate=learning_rate, \n",
    "                            decay_rate=decay_rate, \n",
    "                            plot=plot)\n",
    "model_params.print_explanation()\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing the trained model: DHR +++++++++++++++++++++++\n",
      "Test function input: DHR ['trained_models/DHR_11100_0.001_0_5_100_20240509-155916.pth', 'trained_models/DHR_21100_0.001_0_5_100_20240509-160207.pth', 'trained_models/DHR_31100_0.001_0_10_100_20240508-120807.pth', 'trained_models/DHR_41100_0.001_0_5_100_20240509-133824.pth', 'trained_models/DHR_51100_0.001_0_5_100_20240509-140837.pth'] dataset0_sup0_image1_points0_loss_image0 20240511-223738\n",
      "Test eye dataset\n",
      "Number of testing data:  100\n",
      "\n",
      "Loading model: trained_models/DHR_11100_0.001_0_5_100_20240509-155916.pth\n",
      "Using DHR difference\n",
      "\n",
      "Loading model: trained_models/DHR_21100_0.001_0_5_100_20240509-160207.pth\n",
      "Using DHR difference\n",
      "\n",
      "Loading model: trained_models/DHR_31100_0.001_0_10_100_20240508-120807.pth\n",
      "Using DHR difference\n",
      "\n",
      "Loading model: trained_models/DHR_41100_0.001_0_5_100_20240509-133824.pth\n",
      "Using DHR difference\n",
      "\n",
      "Loading model: trained_models/DHR_51100_0.001_0_5_100_20240509-140837.pth\n",
      "Using DHR difference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing::  41%|████      | 41/100 [00:03<00:05, 10.36it/s]/home/pakpoom/codes/spppt-2/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/pakpoom/codes/spppt-2/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Testing:: 100%|██████████| 100/100 [00:09<00:00, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.08337500e+03 3.72340894e+03 9.03580093e+01 8.62562943e+01\n",
      "  3.98883931e-02 2.69628745e-02 4.10601044e-01 4.69665606e-01\n",
      "  8.00000000e+00]\n",
      " [4.08125000e+02 2.13803268e+02 2.82771091e+01 1.94523640e+01\n",
      "  3.21540907e-02 2.42718309e-02 5.18360528e-01 5.50403010e-01\n",
      "  3.60000000e+01]]\n",
      "The test results are saved in output/DHR_00100_0.001_0_1_1_20240511-223738_ensemble_test/metrics.csv\n",
      "Test model finished +++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTesting the trained model: {model} +++++++++++++++++++++++\")\n",
    "\n",
    "csv_file, metrics = test(model, model_path, model_params, timestamp)\n",
    "print(\"Test model finished +++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.25539973e+02, 2.58785015e+01, 2.30344242e+01, 3.15154436e-02,\n",
       "       2.82836270e-02, 4.50214391e-01, 4.83311640e-01, 4.45252525e+01])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(metrics[:, 1:9], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.08125000e+02, 2.13803268e+02, 2.82771091e+01, 1.94523640e+01,\n",
       "       3.21540907e-02, 2.42718309e-02, 5.18360528e-01, 5.50403010e-01,\n",
       "       3.60000000e+01])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
