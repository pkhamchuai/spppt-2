SP_Rigid
trained_models/SP_Rigid_11010_0.01_0_100_1_20231228-161022.pth
11010_0.01_0_100_1

Model name:  dataset1_sup1_image0_points1_loss_image0
Model code:  11010_0.01_0_100_1
Dataset used:  Synthetic eye easy
Supervised or unsupervised model:  Supervised
Loss image type:  Loss image not used
Points used:  Points used
Loss function case:  0
Loss function for image:  MSELoss()
Loss function for affine:  <utils.utils1.loss_affine object at 0x7f3aea4f1b70>
Learning rate:  0.01
Decay rate:  0.96
Start epoch:  0
Number of epochs:  100
Batch size:  1


[1, 420.4500986480713, 136.7776084804535]
[2, 112.79129557609558, 136.23579207658767]
[3, 112.44893261432648, 136.23572824954988]
[4, 112.49933045864105, 136.23572824954988]
[5, 112.46875, 136.23572824954988]
[6, 112.50484009742736, 136.23572824954988]
[7, 112.44961863517761, 136.23572824954988]
[8, 112.48588718414307, 136.23572824954988]
[9, 112.52323092460632, 136.23572824954988]
[10, 112.4824275636673, 136.23572824954988]
[11, 112.48750022411346, 136.23572824954988]
[12, 112.44809920787812, 136.23572824954988]
[13, 112.50634563446044, 136.23572824954988]
[14, 112.51133075714111, 136.23572824954988]
[15, 112.47416299819946, 136.23572824954988]
[16, 112.53959273815155, 136.23572824954988]
[17, 112.45618503570557, 136.23572824954988]
[18, 112.48944311618806, 136.23572824954988]
[19, 112.44743159770965, 136.23572824954988]
[20, 112.49804443836211, 136.23572824954988]
[21, 112.4702013874054, 136.23572824954988]
[22, 112.4810332775116, 136.23572824954988]
[23, 112.51462019443512, 136.23572824954988]
[24, 112.50508069992065, 136.23572824954988]
[25, 112.50480559825897, 136.23572824954988]
[26, 112.47157296180725, 136.23572824954988]
[27, 112.42185976982117, 136.23572824954988]
[28, 112.45393127918243, 136.23572824954988]
[29, 112.45298592567444, 136.23572824954988]
[30, 112.46960832595825, 136.23572824954988]
[31, 112.43833387851716, 136.23572824954988]
[32, 112.46246243476868, 136.23572824954988]
[33, 112.44214314937591, 136.23572824954988]
[34, 112.47839922904969, 136.23572824954988]
[35, 112.52406569480895, 136.23572824954988]
[36, 112.52114237308503, 136.23572824954988]
[37, 112.44690398216248, 136.23572824954988]
[38, 112.47056416511536, 136.23572824954988]
[39, 112.50440462112427, 136.23572824954988]
[40, 112.50331489086152, 136.23572824954988]
[41, 112.4981404542923, 136.23572824954988]
[42, 112.47798383712768, 136.23572824954988]
[43, 112.45658051013946, 136.23572824954988]
[44, 112.45143940925598, 136.23572824954988]
[45, 112.48890164852142, 136.23572824954988]
[46, 112.46122028827668, 136.23572824954988]
[47, 112.43142794132233, 136.23572824954988]
[48, 112.47709335327148, 136.23572824954988]
[49, 112.43827554225922, 136.23572824954988]
[50, 112.48925724029542, 136.23572824954988]
[51, 112.47211143016816, 136.23572824954988]
[52, 112.52386444568634, 136.23572824954988]
[53, 112.49354755401612, 136.23572824954988]
[54, 112.52769552707672, 136.23572824954988]
[55, 112.5150362586975, 136.23572824954988]
[56, 112.40039696216583, 136.23572824954988]
[57, 112.48208497047425, 136.23572824954988]
[58, 112.45768757343292, 136.23572824954988]
[59, 112.4122095823288, 136.23572824954988]
[60, 112.45644326210022, 136.23572824954988]
[61, 112.51481459617615, 136.23572824954988]
[62, 112.49775404930115, 136.23572824954988]
[63, 112.47061617851257, 136.23572824954988]
[64, 112.48678209781647, 136.23572824954988]
[65, 112.53210377693176, 136.23572824954988]
[66, 112.47541296958923, 136.23572824954988]
[67, 112.42655651569366, 136.23572824954988]
[68, 112.48725396156311, 136.23572824954988]
[69, 112.45575895309449, 136.23572824954988]
[70, 112.48310028553009, 136.23572824954988]
[71, 112.53846056938171, 136.23572824954988]
[72, 112.49124754905701, 136.23572824954988]
[73, 112.49509135246277, 136.23572824954988]
[74, 112.50990522384643, 136.23572824954988]
[75, 112.46810022830964, 136.23572824954988]
[76, 112.48911135673524, 136.23572824954988]
[77, 112.48457640647888, 136.23572824954988]
[78, 112.45314817428589, 136.23572824954988]
[79, 112.47068933963776, 136.23572824954988]
[80, 112.50368138313293, 136.23572824954988]
[81, 112.48043468475342, 136.23572824954988]
[82, 112.44234614372253, 136.23572824954988]
[83, 112.51187826156617, 136.23572824954988]
[84, 112.48878723621368, 136.23572824954988]
[85, 112.45716050624847, 136.23572824954988]
[86, 112.49797080516815, 136.23572824954988]
[87, 112.5002214050293, 136.23572824954988]
[88, 112.45220005989074, 136.23572824954988]
[89, 112.5247959947586, 136.23572824954988]
[90, 112.4326802110672, 136.23572824954988]
[91, 112.41372149944306, 136.23572824954988]
[92, 112.47492337226868, 136.23572824954988]
[93, 112.46237339496612, 136.23572824954988]
[94, 112.47276391506195, 136.23572824954988]
[95, 112.51773228645325, 136.23572824954988]
[96, 112.52452372074127, 136.23572824954988]
[97, 112.52553155899048, 136.23572824954988]
[98, 112.50251203060151, 136.23572824954988]
[99, 112.42997798919677, 136.23572824954988]
[100, 112.4465736246109, 136.23572824954988]
