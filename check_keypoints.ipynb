{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if the keypoints are duplicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\\wsl.localhost\\Ubuntu\\home\\pkhamchuai\\codes\\spppt-2\\output\\SIFT\\SIFT_20100_0.0001_0_1_1_20240705-150230_BFMatcher_RANSAC_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from run_SP import *\n",
    "from utils.utils1 import draw_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model_params, method='LMEDS', plot=1):\n",
    "    # Initialize SuperPointFrontend\n",
    "    superpoint = SuperPointFrontend('utils/superpoint_v1.pth', nms_dist=4,\n",
    "                          conf_thresh=0.015,\n",
    "                          nn_thresh=0.7, cuda=True)\n",
    "    \n",
    "    test_dataset = datagen(model_params.dataset, False, model_params.sup)\n",
    "\n",
    "    # Create output directory\n",
    "    output_dir = f\"output/{args.model}_{model_params.get_model_code()}_{timestamp}_{method}_test\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    metrics = []\n",
    "    # create a csv file to store the metrics\n",
    "    csv_file = f\"{output_dir}/metrics.csv\"\n",
    "\n",
    "    testbar = tqdm(test_dataset, desc=f'Testing:')\n",
    "    for i, data in enumerate(testbar, 0):\n",
    "        if i != 90:\n",
    "            continue\n",
    "        if i == 90:\n",
    "            # Get images and affine parameters\n",
    "            source_image, target_image, affine_params_true, points1, points2, points1_2_true = data\n",
    "                \n",
    "            # process images\n",
    "            source_image = process_image(source_image)\n",
    "            target_image = process_image(target_image)\n",
    "\n",
    "            # need to perform superpoint again because descriptors are not saved\n",
    "            # Process the first image\n",
    "            points1, desc1, heatmap1 = superpoint(source_image)\n",
    "            # Process the second image\n",
    "            points2, desc2, heatmap2 = superpoint(target_image)\n",
    "\n",
    "            # match the points between the two images\n",
    "            tracker = PointTracker(5, nn_thresh=0.7)\n",
    "            matches = tracker.nn_match_two_way(desc1, desc2, nn_thresh=0.7)\n",
    "\n",
    "            # take the elements from points1 and points2 using the matches as indices\n",
    "            matches1 = points1[:2, matches[0, :].astype(int)]\n",
    "            matches2 = points2[:2, matches[1, :].astype(int)]\n",
    "\n",
    "            # create affine transform matrix from points1 to points2\n",
    "            # and apply it to points1\n",
    "            try:\n",
    "                if method == 'RANSAC':\n",
    "                    affine_transform1 = cv2.estimateAffinePartial2D(matches1.T, matches2.T, method=cv2.RANSAC)\n",
    "                elif method == 'LMEDS':\n",
    "                    affine_transform1 = cv2.estimateAffinePartial2D(matches1.T, matches2.T, method=cv2.LMEDS)\n",
    "                matches1_transformed = cv2.transform(matches1.T[None, :, :], affine_transform1[0])\n",
    "                matches1_transformed = matches1_transformed[0].T\n",
    "                # transform image 1 and 2 using the affine transform matrix\n",
    "                transformed_source_affine = cv2.warpAffine(source_image, affine_transform1[0], (256, 256))\n",
    "            except cv2.error:\n",
    "                print(f\"Error: {i}\")\n",
    "                # set affine_transform1 to identity affine matrix\n",
    "                affine_transform1 = np.array([[[1, 0, 0], [0, 1, 0]]])\n",
    "                matches1_transformed = matches1\n",
    "                transformed_source_affine = source_image\n",
    "            \n",
    "            # mse12 = np.mean((matches1_transformed - matches2)**2)\n",
    "            # tre12 = np.mean(np.sqrt(np.sum((matches1_transformed - matches2)**2, axis=0)))\n",
    "\n",
    "            if i < 100 and plot == 1:\n",
    "                plot_ = 1\n",
    "            elif i < 100 and plot == 2:\n",
    "                plot_ = 2\n",
    "            else:\n",
    "                plot_ = 0\n",
    "\n",
    "            results = DL_affine_plot(f\"test\", output_dir,\n",
    "                    f\"{i}\", \"SP\", source_image, target_image, \\\n",
    "                    transformed_source_affine, \\\n",
    "                    matches1, matches2, matches1_transformed, desc1, desc2, \n",
    "                    affine_params_true=affine_params_true,\n",
    "                    affine_params_predict=affine_transform1[0], \n",
    "                    heatmap1=heatmap1, heatmap2=heatmap2, plot=plot_)\n",
    "\n",
    "\n",
    "            # calculate metrics\n",
    "            # matches1_transformed = results[0]\n",
    "            mse_before = results[1]\n",
    "            mse12 = results[2]\n",
    "            tre_before = results[3]\n",
    "            tre12 = results[4]\n",
    "            mse12_image_before = results[5]\n",
    "            mse12_image = results[6]\n",
    "            ssim12_image_before = results[7]\n",
    "            ssim12_image = results[8]\n",
    "\n",
    "    return source_image, target_image, transformed_source_affine, matches1, matches2, matches1_transformed\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataset DATASET] [--sup SUP]\n",
      "                             [--image IMAGE] [--heatmaps HEATMAPS]\n",
      "                             [--loss_image LOSS_IMAGE]\n",
      "                             [--num_epochs NUM_EPOCHS]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--decay_rate DECAY_RATE] [--model MODEL]\n",
      "                             [--model_path MODEL_PATH] [--plot PLOT]\n",
      "                             [--method METHOD]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/home/pkhamchuai/.local/share/jupyter/runtime/kernel-v2-3264JdBR7U1JI62t.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pkhamchuai/codes/spppt-2/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Deep Learning for Image Registration')    \n",
    "    parser.add_argument('--dataset', type=int, default=2, help='dataset number')\n",
    "    parser.add_argument('--sup', type=int, default=1, help='supervised learning (1) or unsupervised learning (0)')\n",
    "    parser.add_argument('--image', type=int, default=1, help='image used for training')\n",
    "    parser.add_argument('--heatmaps', type=int, default=0, help='use heatmaps (1) or not (0)')\n",
    "    parser.add_argument('--loss_image', type=int, default=0, help='loss function for image registration')\n",
    "    parser.add_argument('--num_epochs', type=int, default=1, help='number of epochs')\n",
    "    parser.add_argument('--learning_rate', type=float, default=1e-4, help='learning rate')\n",
    "    parser.add_argument('--decay_rate', type=float, default=0.96, help='decay rate')\n",
    "    parser.add_argument('--model', type=str, default='SP', help='which model to use')\n",
    "    parser.add_argument('--model_path', type=str, default=None, help='path to model to load')\n",
    "    parser.add_argument('--plot', type=int, default=1, help='plot the results')\n",
    "    parser.add_argument('--method', type=str, default='LMEDS', help='method to use for affine transformation')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    model_params = ModelParams(dataset=args.dataset, sup=args.sup, image=args.image, #heatmaps=args.heatmaps, \n",
    "                                loss_image=args.loss_image, num_epochs=args.num_epochs, \n",
    "                                learning_rate=args.learning_rate, decay_rate=args.decay_rate)\n",
    "    model_params.print_explanation()\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    # run the function\n",
    "    source_image, target_image, transformed_source_affine, matches1, matches2, matches1_transformed = run(model_params, method='RANSAC', plot=1)\n",
    "\n",
    "    # plot the images\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax[0].imshow(source_image, cmap='gray')\n",
    "    ax[0].scatter(matches1[0], matches1[1], c='r', s=5)\n",
    "    ax[0].set_title('Source Image')\n",
    "    ax[1].imshow(target_image, cmap='gray')\n",
    "    ax[1].scatter(matches2[0], matches2[1], c='r', s=5)\n",
    "    ax[1].set_title('Target Image')\n",
    "    ax[2].imshow(transformed_source_affine, cmap='gray')\n",
    "    ax[2].scatter(matches1_transformed[0], matches1_transformed[1], c='r', s=5)\n",
    "    ax[2].set_title('Transformed Source Image')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
