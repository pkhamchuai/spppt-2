{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data\n",
    "Read both affine params and points, the normal datagen pipeline for training should do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from utils.utils0 import *\n",
    "from utils.utils1 import *\n",
    "from utils.utils1 import ModelParams, model_loader, print_summary#, test_repeat\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:  dataset2_sup1_image1_points0_loss_image0\n",
      "Model code:  21100_0.001_0_10_1\n",
      "Model params:  {'dataset': 2, 'sup': 1, 'image': 1, 'points': 0, 'loss_image_case': 0, 'loss_image': MSELoss(), 'loss_affine': <utils.utils1.loss_affine object at 0x7f62b407db80>, 'learning_rate': 0.001, 'decay_rate': 0.96, 'start_epoch': 0, 'num_epochs': 10, 'batch_size': 1, 'model_name': 'dataset2_sup1_image1_points0_loss_image0'}\n"
     ]
    }
   ],
   "source": [
    "model_params = ModelParams(dataset=2, sup=1)\n",
    "train_dataset = datagen(model_params.dataset, True, model_params.sup)\n",
    "test_dataset = datagen(model_params.dataset, False, model_params.sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a pair of images from the test set\n",
    "outputs = list(train_dataset)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256, 256])\n",
      "torch.Size([1, 1, 256, 256])\n",
      "torch.Size([1, 2, 3])\n",
      "torch.Size([1, 81, 2])\n",
      "torch.Size([1, 81, 2])\n",
      "torch.Size([1, 81, 2])\n"
     ]
    }
   ],
   "source": [
    "for output in outputs:\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define NN model\n",
    "- Input: affine parms (2x3), original points (2x1)\n",
    "- Output: predicted transformed points (2x1)\n",
    "- Groundtruth: true transformed points (2x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AffineTransformationNetwork(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of parameters: 6\n"
     ]
    }
   ],
   "source": [
    "class AffineTransformationNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(AffineTransformationNetwork, self).__init__()\n",
    "\n",
    "        # Check if hidden_sizes is empty\n",
    "        if not hidden_sizes:\n",
    "            self.hidden_layers = nn.ModuleList([])\n",
    "            self.fc = nn.Linear(input_size, output_size)\n",
    "        else:\n",
    "            layers = [nn.Linear(input_size, hidden_sizes[0]), nn.ReLU(), nn.Dropout(0.1)]\n",
    "            for i in range(1, len(hidden_sizes)):\n",
    "                layers += [nn.Linear(hidden_sizes[i - 1], hidden_sizes[i]), nn.ReLU(), nn.Dropout(0.1)]\n",
    "            layers += [nn.Linear(hidden_sizes[-1], output_size)]\n",
    "            self.hidden_layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, affine_matrix, point):\n",
    "        # Flatten and concatenate the input matrices\n",
    "        input_data = torch.cat((affine_matrix, point))\n",
    "\n",
    "        # Pass the input through hidden layers\n",
    "        for layer in self.hidden_layers:\n",
    "            input_data = layer(input_data)\n",
    "\n",
    "        # Reshape the output to (2x1)\n",
    "        transformed_point = input_data#.view(2)\n",
    "\n",
    "        return transformed_point\n",
    "\n",
    "# Example: Create an instance of the neural network with 2 hidden layers and 64 neurons in each hidden layer\n",
    "input_size = 8  # Affine matrix (2x3) + Point (2)\n",
    "num_hidden_layers = 2\n",
    "num_perceptrons = 64\n",
    "hidden_sizes = num_hidden_layers*[num_perceptrons]\n",
    "output_size = 2  # Transformed point (2)\n",
    "\n",
    "model = AffineTransformationNetwork(input_size, hidden_sizes, output_size)\n",
    "print(model)\n",
    "model.to(device)\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "parameters = list(model.parameters())\n",
    "print(f'Number of parameters: {len(parameters)}')\n",
    "# print(f'Parameters: {parameters}')\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1400, gamma=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 14/200 [00:00<00:03, 54.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [00:03<00:00, 62.31it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:01<00:00, 76.70it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset_new = []\n",
    "# loop through all items in the train_dataset \n",
    "# and modify the input and output as described above\n",
    "train_bar = tqdm(train_dataset, desc='Training')\n",
    "# Loop over all training examples\n",
    "for i, (source_img, target_img, affine_params, \\\n",
    "        matches1, matches2, matches1_2) in enumerate(train_bar):\n",
    "    for j in range(matches1.shape[1]):\n",
    "        train_dataset_new.append((torch.cat((affine_params.view(-1), matches1[0][j])), matches2[0][j]))\n",
    "        if j > 3:\n",
    "            break   \n",
    "\n",
    "test_dataset_new = []\n",
    "# loop through all items in the train_dataset \n",
    "# and modify the input and output as described above\n",
    "test_bar = tqdm(test_dataset, desc='Testing')\n",
    "# Loop over all training examples\n",
    "for i, (source_img, target_img, affine_params, \\\n",
    "        matches1, matches2, matches1_2) in enumerate(test_bar):\n",
    "    for j in range(matches1.shape[1]):\n",
    "        test_dataset_new.append((torch.cat((affine_params.view(-1), matches1[0][j])), matches2[0][j]))\n",
    "        if j > 1:\n",
    "            break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create empty list to store epoch number, train loss and validation loss\n",
    "# epoch_loss_list = []\n",
    "# running_loss_list = []\n",
    "# val_loss_list = []\n",
    "# print('Seed:', torch.seed())\n",
    "\n",
    "# # Training loop\n",
    "# epochs = 1000\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "    \n",
    "#     # optimizer.zero_grad()\n",
    "#     running_loss = 0.0\n",
    "    \n",
    "#     train_bar = tqdm(train_dataset_new, desc='Training Epoch %d/%d' % (epoch+1, epochs))\n",
    "#     # Loop over all training examples\n",
    "#     for i, (input, matches1_2) in enumerate(train_bar):\n",
    "#         optimizer.zero_grad()\n",
    "#         # Set the inputs and labels to the training device\n",
    "#         # source_img = source_img.to(device)\n",
    "#         # target_img = target_img.to(device)\n",
    "#         affine_params = input[:6].to(device)\n",
    "#         matches1 = input[6:].to(device)\n",
    "#         # matches2 = matches2.to(device)\n",
    "#         matches1_2 = matches1_2.to(device)\n",
    "\n",
    "#         # optimizer.zero_grad()\n",
    "#         # for j in range(matches1.shape[1]):\n",
    "#         # Forward pass\n",
    "#         predicted_points = model(affine_params, matches1)\n",
    "\n",
    "#         # Compute the loss\n",
    "#         loss = criterion(predicted_points, matches1_2)\n",
    "\n",
    "#         running_loss += loss.item()\n",
    "        \n",
    "#         train_bar.set_postfix({'loss': running_loss / (i+1)})\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     scheduler.step()\n",
    "#     epoch_loss_list.append(running_loss / len(train_dataset_new))\n",
    "#     # if epoch % 10 == 0:\n",
    "#     #     print(f'Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_dataset_new)}')\n",
    "\n",
    "#     # Validation loop\n",
    "#     model.eval()\n",
    "\n",
    "#     val_running_loss = 0.0\n",
    "\n",
    "#     test_bar = tqdm(test_dataset_new, desc='Testing Epoch %d/%d' % (epoch+1, epochs))\n",
    "#     # Loop over all validation examples\n",
    "#     for i, (input, matches1_2) in enumerate(test_bar):\n",
    "#         # Set the inputs and labels to the validation device\n",
    "#         # source_img = source_img.to(device)\n",
    "#         # target_img = target_img.to(device)\n",
    "#         affine_params = input[:6].to(device)\n",
    "#         matches1 = input[6:].to(device)\n",
    "#         # matches2 = matches2.to(device)\n",
    "#         matches1_2 = matches1_2.to(device)\n",
    "\n",
    "#         # Forward pass\n",
    "#         predicted_points = model(affine_params, matches1)\n",
    "\n",
    "#         # Compute the loss\n",
    "#         loss = criterion(predicted_points, matches1_2)\n",
    "\n",
    "#         val_running_loss += loss.item()\n",
    "#         test_bar.set_postfix({'loss': val_running_loss / (i+1)})\n",
    "\n",
    "#     val_loss_list.append(val_running_loss / len(test_dataset_new))\n",
    "#     # if epoch % 10 == 0:\n",
    "#     #     print(f'Epoch [{epoch + 1}/{epochs}], Val Loss: {val_running_loss / len(test_dataset_new)}')\n",
    "\n",
    "#     # Save the model if the validation loss is the lowest we've seen so far\n",
    "#     # if val_loss_list[-1] == min(val_loss_list):\n",
    "#     #     torch.save(model.state_dict(), f'trained_models/affine_NN_{epoch:03d}.pth')\n",
    "#     #     print('Model saved')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save model to file train_model/affine_transformation_network.pt\n",
    "# torch.save(model.state_dict(), f'trained_models/affine_NN_{num_hidden_layers}_{num_perceptrons}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Plot train loss and validation loss against epoch number\n",
    "# fig = plt.figure(figsize=(10, 5))\n",
    "# plt.plot(range(1, epochs+1), epoch_loss_list, label='Running Train Loss', linewidth=3)\n",
    "# plt.plot(range(1, epochs+1), val_loss_list, label='Running Validation Loss', linewidth=3)\n",
    "# plt.title('Train Loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.grid(True)\n",
    "# # plt.yscale('log')\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Save plot\n",
    "# # signaturebar_gray(fig, f'{model_params.get_model_code()} - epoch{model_params.num_epochs} - {timestamp}')\n",
    "# # fig.savefig(save_plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AffineTransformationNetwork(\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=8, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "input_size = 8  # Affine matrix (2x3) + Point (2)\n",
    "num_hidden_layers = 2\n",
    "num_perceptrons = 64\n",
    "hidden_sizes = num_hidden_layers*[num_perceptrons]\n",
    "model = AffineTransformationNetwork(input_size, hidden_sizes, output_size)\n",
    "# model.load_state_dict(torch.load(f'trained_models/affine_NN_{num_hidden_layers}_{num_perceptrons}.pth'))\n",
    "model.load_state_dict(torch.load(f'trained_models/affine_NN_2_64_2000_20231220_200233.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   4%|▎         | 11/300 [00:00<00:02, 131.63it/s, loss=5.77]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [ 79. 140.], Predicted: [ 68.33421 145.55869]\n",
      "True: [98. 68.], Predicted: [90.15383 84.63431]\n",
      "True: [221. 132.], Predicted: [182.98907 135.83365]\n",
      "True: [ 23. 170.], Predicted: [ 43.54608 138.3555 ]\n",
      "True: [212. 211.], Predicted: [214.14929 165.19345]\n",
      "True: [ 10. 105.], Predicted: [32.144115 78.57881 ]\n",
      "True: [113. 118.], Predicted: [130.6988 122.4299]\n",
      "True: [165.  46.], Predicted: [177.16812  73.19113]\n",
      "True: [36. 50.], Predicted: [50.301846 78.6088  ]\n",
      "True: [175.  35.], Predicted: [167.07      55.677673]\n",
      "True: [128.  20.], Predicted: [130.94019  44.48124]\n",
      "True: [120. 106.], Predicted: [123.69107 117.1729 ]\n",
      "Mean test loss: 422.3936487833659, Std test loss: 293.5627552739249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_loss_list = []\n",
    "test_bar = tqdm(test_dataset_new, desc='Testing')\n",
    "for i, (input, matches1_2) in enumerate(test_bar):\n",
    "    # Set the inputs and labels to the training device\n",
    "    # source_img = source_img.to(device)\n",
    "    # target_img = target_img.to(device)\n",
    "    affine_params = input[:6].to(device)\n",
    "    matches1 = input[6:].to(device)\n",
    "    # matches2 = matches2.to(device)\n",
    "    matches1_2 = matches1_2.to(device)\n",
    "\n",
    "    # optimizer.zero_grad()\n",
    "    # for j in range(matches1.shape[1]):\n",
    "    # Forward pass\n",
    "    predicted_points = model(affine_params, matches1)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(predicted_points, matches1_2)\n",
    "\n",
    "    test_loss_list.append(loss.item())\n",
    "\n",
    "    test_bar.set_postfix({'loss': loss.item() / (i+1)})\n",
    "    print(f'True: {matches1_2.detach().cpu().numpy()}, Predicted: {predicted_points.detach().cpu().numpy()}')\n",
    "    if i > 10:\n",
    "        break\n",
    "\n",
    "# mean and std of the test loss\n",
    "mean_test_loss = np.mean(test_loss_list)\n",
    "std_test_loss = np.std(test_loss_list)\n",
    "print(f'Mean test loss: {mean_test_loss}, Std test loss: {std_test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spppt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
