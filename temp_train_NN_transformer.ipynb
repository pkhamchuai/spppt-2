{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data\n",
    "Read both affine params and points, the normal datagen pipeline for training should do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from utils.utils0 import *\n",
    "from utils.utils1 import *\n",
    "from utils.utils1 import ModelParams, model_loader, print_summary#, test_repeat\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:  dataset2_sup1_image1_points0_loss_image0\n",
      "Model code:  21100_0.001_0_10_1\n",
      "Model params:  {'dataset': 2, 'sup': 1, 'image': 1, 'points': 0, 'loss_image_case': 0, 'loss_image': MSELoss(), 'loss_affine': <utils.utils1.loss_affine object at 0x7f89de380d90>, 'learning_rate': 0.001, 'decay_rate': 0.96, 'start_epoch': 0, 'num_epochs': 10, 'batch_size': 1, 'model_name': 'dataset2_sup1_image1_points0_loss_image0'}\n"
     ]
    }
   ],
   "source": [
    "model_params = ModelParams(dataset=2, sup=1)\n",
    "train_dataset = datagen(model_params.dataset, True, model_params.sup)\n",
    "test_dataset = datagen(model_params.dataset, False, model_params.sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a pair of images from the test set\n",
    "outputs = list(train_dataset)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256, 256])\n",
      "torch.Size([1, 1, 256, 256])\n",
      "torch.Size([1, 2, 3])\n",
      "torch.Size([1, 65, 2])\n",
      "torch.Size([1, 65, 2])\n",
      "torch.Size([1, 65, 2])\n"
     ]
    }
   ],
   "source": [
    "for output in outputs:\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define NN model\n",
    "- Input: affine parms (2x3), original points (2x1)\n",
    "- Output: predicted transformed points (2x1)\n",
    "- Groundtruth: true transformed points (2x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AffineTransformationNetwork(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of parameters: 8\n"
     ]
    }
   ],
   "source": [
    "class AffineTransformationNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(AffineTransformationNetwork, self).__init__()\n",
    "\n",
    "        # Check if hidden_sizes is empty\n",
    "        if not hidden_sizes:\n",
    "            self.hidden_layers = nn.ModuleList([])\n",
    "            self.fc = nn.Linear(input_size, output_size)\n",
    "        else:\n",
    "            layers = [nn.Linear(input_size, hidden_sizes[0]), nn.ReLU(), nn.Dropout(0.1)]\n",
    "            for i in range(1, len(hidden_sizes)):\n",
    "                layers += [nn.Linear(hidden_sizes[i - 1], hidden_sizes[i]), nn.ReLU(), nn.Dropout(0.1)]\n",
    "            layers += [nn.Linear(hidden_sizes[-1], output_size)]\n",
    "            self.hidden_layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, affine_matrix, point):\n",
    "        # Flatten and concatenate the input matrices\n",
    "        input_data = torch.cat((affine_matrix, point))\n",
    "\n",
    "        # Pass the input through hidden layers\n",
    "        for layer in self.hidden_layers:\n",
    "            input_data = layer(input_data)\n",
    "\n",
    "        # Reshape the output to (2x1)\n",
    "        transformed_point = input_data#.view(2)\n",
    "\n",
    "        return transformed_point\n",
    "\n",
    "# Example: Create an instance of the neural network with 2 hidden layers and 64 neurons in each hidden layer\n",
    "input_size = 8  # Affine matrix (2x3) + Point (2)\n",
    "num_hidden_layers = 3\n",
    "num_perceptrons = 64\n",
    "hidden_sizes = num_hidden_layers*[num_perceptrons]\n",
    "output_size = 2  # Transformed point (2)\n",
    "\n",
    "model = AffineTransformationNetwork(input_size, hidden_sizes, output_size)\n",
    "print(model)\n",
    "model.to(device)\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "parameters = list(model.parameters())\n",
    "print(f'Number of parameters: {len(parameters)}')\n",
    "# print(f'Parameters: {parameters}')\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1400, gamma=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 200/200 [00:02<00:00, 70.29it/s]\n",
      "Testing: 100%|██████████| 100/100 [00:01<00:00, 83.32it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset_new = []\n",
    "# loop through all items in the train_dataset \n",
    "# and modify the input and output as described above\n",
    "train_bar = tqdm(train_dataset, desc='Training')\n",
    "# Loop over all training examples\n",
    "for i, (source_img, target_img, affine_params, \\\n",
    "        matches1, matches2, matches1_2) in enumerate(train_bar):\n",
    "    for j in range(matches1.shape[1]):\n",
    "        train_dataset_new.append((torch.cat((affine_params.view(-1), matches1[0][j])), matches2[0][j]))\n",
    "        if j > 5:\n",
    "            break   \n",
    "\n",
    "test_dataset_new = []\n",
    "# loop through all items in the train_dataset \n",
    "# and modify the input and output as described above\n",
    "test_bar = tqdm(test_dataset, desc='Testing')\n",
    "# Loop over all training examples\n",
    "for i, (source_img, target_img, affine_params, \\\n",
    "        matches1, matches2, matches1_2) in enumerate(test_bar):\n",
    "    for j in range(matches1.shape[1]):\n",
    "        test_dataset_new.append((torch.cat((affine_params.view(-1), matches1[0][j])), matches2[0][j]))\n",
    "        if j > 2:\n",
    "            break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 13062070435721758420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/1000: 100%|██████████| 1400/1400 [00:11<00:00, 118.31it/s, loss=1.33e+3]\n",
      "Testing Epoch 1/1000: 100%|██████████| 400/400 [00:01<00:00, 212.73it/s, loss=454]\n",
      "Training Epoch 2/1000: 100%|██████████| 1400/1400 [00:10<00:00, 127.69it/s, loss=743]  \n",
      "Testing Epoch 2/1000: 100%|██████████| 400/400 [00:01<00:00, 211.14it/s, loss=431]\n",
      "Training Epoch 3/1000: 100%|██████████| 1400/1400 [00:11<00:00, 120.45it/s, loss=699]  \n",
      "Testing Epoch 3/1000: 100%|██████████| 400/400 [00:01<00:00, 206.28it/s, loss=451]\n",
      "Training Epoch 4/1000: 100%|██████████| 1400/1400 [00:12<00:00, 115.66it/s, loss=728]\n",
      "Testing Epoch 4/1000: 100%|██████████| 400/400 [00:01<00:00, 206.63it/s, loss=317]\n",
      "Training Epoch 5/1000: 100%|██████████| 1400/1400 [00:12<00:00, 113.49it/s, loss=687]   \n",
      "Testing Epoch 5/1000: 100%|██████████| 400/400 [00:01<00:00, 203.33it/s, loss=307]\n",
      "Training Epoch 6/1000: 100%|██████████| 1400/1400 [00:12<00:00, 108.06it/s, loss=710]\n",
      "Testing Epoch 6/1000: 100%|██████████| 400/400 [00:02<00:00, 182.28it/s, loss=471]\n",
      "Training Epoch 7/1000: 100%|██████████| 1400/1400 [00:13<00:00, 107.09it/s, loss=689]\n",
      "Testing Epoch 7/1000: 100%|██████████| 400/400 [00:02<00:00, 182.38it/s, loss=346]\n",
      "Training Epoch 8/1000: 100%|██████████| 1400/1400 [00:13<00:00, 106.62it/s, loss=745]   \n",
      "Testing Epoch 8/1000: 100%|██████████| 400/400 [00:01<00:00, 201.65it/s, loss=407]\n",
      "Training Epoch 9/1000: 100%|██████████| 1400/1400 [00:12<00:00, 111.05it/s, loss=680]  \n",
      "Testing Epoch 9/1000: 100%|██████████| 400/400 [00:01<00:00, 216.18it/s, loss=403]\n",
      "Training Epoch 10/1000: 100%|██████████| 1400/1400 [00:12<00:00, 114.03it/s, loss=669]\n",
      "Testing Epoch 10/1000: 100%|██████████| 400/400 [00:01<00:00, 209.74it/s, loss=322]\n",
      "Training Epoch 11/1000: 100%|██████████| 1400/1400 [00:12<00:00, 108.76it/s, loss=655]\n",
      "Testing Epoch 11/1000: 100%|██████████| 400/400 [00:02<00:00, 198.93it/s, loss=460]\n",
      "Training Epoch 12/1000: 100%|██████████| 1400/1400 [00:12<00:00, 114.56it/s, loss=677]  \n",
      "Testing Epoch 12/1000: 100%|██████████| 400/400 [00:02<00:00, 195.89it/s, loss=297]\n",
      "Training Epoch 13/1000: 100%|██████████| 1400/1400 [00:12<00:00, 108.49it/s, loss=708]   \n",
      "Testing Epoch 13/1000: 100%|██████████| 400/400 [00:01<00:00, 211.33it/s, loss=388]\n",
      "Training Epoch 14/1000: 100%|██████████| 1400/1400 [00:12<00:00, 114.28it/s, loss=666]\n",
      "Testing Epoch 14/1000: 100%|██████████| 400/400 [00:02<00:00, 168.74it/s, loss=384]\n",
      "Training Epoch 15/1000: 100%|██████████| 1400/1400 [00:13<00:00, 102.68it/s, loss=656]   \n",
      "Testing Epoch 15/1000: 100%|██████████| 400/400 [00:02<00:00, 176.92it/s, loss=578]\n",
      "Training Epoch 16/1000: 100%|██████████| 1400/1400 [00:12<00:00, 107.78it/s, loss=624]\n",
      "Testing Epoch 16/1000: 100%|██████████| 400/400 [00:02<00:00, 184.78it/s, loss=293]\n",
      "Training Epoch 17/1000: 100%|██████████| 1400/1400 [00:12<00:00, 112.55it/s, loss=633]\n",
      "Testing Epoch 17/1000: 100%|██████████| 400/400 [00:02<00:00, 183.42it/s, loss=337]\n",
      "Training Epoch 18/1000: 100%|██████████| 1400/1400 [00:12<00:00, 113.77it/s, loss=629]  \n",
      "Testing Epoch 18/1000: 100%|██████████| 400/400 [00:02<00:00, 199.13it/s, loss=362]\n",
      "Training Epoch 19/1000: 100%|██████████| 1400/1400 [00:12<00:00, 115.29it/s, loss=645]\n",
      "Testing Epoch 19/1000: 100%|██████████| 400/400 [00:02<00:00, 190.55it/s, loss=331]\n",
      "Training Epoch 20/1000: 100%|██████████| 1400/1400 [00:12<00:00, 115.94it/s, loss=648]   \n",
      "Testing Epoch 20/1000: 100%|██████████| 400/400 [00:02<00:00, 198.34it/s, loss=369]\n",
      "Training Epoch 21/1000: 100%|██████████| 1400/1400 [00:12<00:00, 114.55it/s, loss=583]\n",
      "Testing Epoch 21/1000: 100%|██████████| 400/400 [00:02<00:00, 187.84it/s, loss=377]\n",
      "Training Epoch 22/1000: 100%|██████████| 1400/1400 [00:12<00:00, 113.24it/s, loss=604]\n",
      "Testing Epoch 22/1000: 100%|██████████| 400/400 [00:02<00:00, 197.56it/s, loss=864]\n",
      "Training Epoch 23/1000: 100%|██████████| 1400/1400 [00:12<00:00, 107.90it/s, loss=595]\n",
      "Testing Epoch 23/1000: 100%|██████████| 400/400 [00:02<00:00, 182.74it/s, loss=548]\n",
      "Training Epoch 24/1000: 100%|██████████| 1400/1400 [00:12<00:00, 111.10it/s, loss=602]\n",
      "Testing Epoch 24/1000: 100%|██████████| 400/400 [00:02<00:00, 173.63it/s, loss=393]\n",
      "Training Epoch 25/1000: 100%|██████████| 1400/1400 [00:13<00:00, 106.77it/s, loss=608]\n",
      "Testing Epoch 25/1000: 100%|██████████| 400/400 [00:02<00:00, 161.29it/s, loss=782]\n",
      "Training Epoch 26/1000: 100%|██████████| 1400/1400 [00:13<00:00, 106.88it/s, loss=612]\n",
      "Testing Epoch 26/1000: 100%|██████████| 400/400 [00:02<00:00, 185.08it/s, loss=461]\n",
      "Training Epoch 27/1000: 100%|██████████| 1400/1400 [00:12<00:00, 110.79it/s, loss=609]\n",
      "Testing Epoch 27/1000: 100%|██████████| 400/400 [00:02<00:00, 175.26it/s, loss=284]\n",
      "Training Epoch 28/1000: 100%|██████████| 1400/1400 [00:12<00:00, 111.35it/s, loss=591]  \n",
      "Testing Epoch 28/1000: 100%|██████████| 400/400 [00:02<00:00, 189.27it/s, loss=357]\n",
      "Training Epoch 29/1000: 100%|██████████| 1400/1400 [00:12<00:00, 110.72it/s, loss=650]\n",
      "Testing Epoch 29/1000: 100%|██████████| 400/400 [00:02<00:00, 176.69it/s, loss=397]\n",
      "Training Epoch 30/1000: 100%|██████████| 1400/1400 [00:12<00:00, 109.03it/s, loss=611]  \n",
      "Testing Epoch 30/1000: 100%|██████████| 400/400 [00:02<00:00, 197.64it/s, loss=606]\n",
      "Training Epoch 31/1000: 100%|██████████| 1400/1400 [00:12<00:00, 108.73it/s, loss=598]\n",
      "Testing Epoch 31/1000: 100%|██████████| 400/400 [00:02<00:00, 189.09it/s, loss=461]\n",
      "Training Epoch 32/1000: 100%|██████████| 1400/1400 [00:13<00:00, 105.84it/s, loss=587]\n",
      "Testing Epoch 32/1000: 100%|██████████| 400/400 [00:02<00:00, 179.72it/s, loss=386]\n",
      "Training Epoch 33/1000: 100%|██████████| 1400/1400 [00:12<00:00, 108.90it/s, loss=610]  \n",
      "Testing Epoch 33/1000: 100%|██████████| 400/400 [00:02<00:00, 191.15it/s, loss=312]\n",
      "Training Epoch 34/1000:  50%|████▉     | 694/1400 [00:06<00:06, 111.69it/s, loss=593]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 41\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     44\u001b[0m epoch_loss_list\u001b[38;5;241m.\u001b[39mappend(running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataset_new))\n",
      "File \u001b[0;32m~/miniconda3/envs/spppt/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:68\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/spppt/lib/python3.8/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spppt/lib/python3.8/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/spppt/lib/python3.8/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/spppt/lib/python3.8/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/spppt/lib/python3.8/site-packages/torch/optim/adam.py:567\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    565\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_exp_avg_sqs)\n\u001b[0;32m--> 567\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_div_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg_sq_sqrt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n\u001b[1;32m    569\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_addcdiv_(device_params, device_exp_avgs, exp_avg_sq_sqrt, step_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create empty list to store epoch number, train loss and validation loss\n",
    "epoch_loss_list = []\n",
    "running_loss_list = []\n",
    "val_loss_list = []\n",
    "print('Seed:', torch.seed())\n",
    "\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # optimizer.zero_grad()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    train_bar = tqdm(train_dataset_new, desc='Training Epoch %d/%d' % (epoch+1, epochs))\n",
    "    # Loop over all training examples\n",
    "    for i, (input, matches1_2) in enumerate(train_bar):\n",
    "        optimizer.zero_grad()\n",
    "        # Set the inputs and labels to the training device\n",
    "        # source_img = source_img.to(device)\n",
    "        # target_img = target_img.to(device)\n",
    "        affine_params = input[:6].to(device)\n",
    "        matches1 = input[6:].to(device)\n",
    "        # matches2 = matches2.to(device)\n",
    "        matches1_2 = matches1_2.to(device)\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "        # for j in range(matches1.shape[1]):\n",
    "        # Forward pass\n",
    "        predicted_points = model(affine_params, matches1)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(predicted_points, matches1_2)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        train_bar.set_postfix({'loss': running_loss / (i+1)})\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    epoch_loss_list.append(running_loss / len(train_dataset_new))\n",
    "    # if epoch % 10 == 0:\n",
    "    #     print(f'Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_dataset_new)}')\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    test_bar = tqdm(test_dataset_new, desc='Testing Epoch %d/%d' % (epoch+1, epochs))\n",
    "    # Loop over all validation examples\n",
    "    for i, (input, matches1_2) in enumerate(test_bar):\n",
    "        # Set the inputs and labels to the validation device\n",
    "        # source_img = source_img.to(device)\n",
    "        # target_img = target_img.to(device)\n",
    "        affine_params = input[:6].to(device)\n",
    "        matches1 = input[6:].to(device)\n",
    "        # matches2 = matches2.to(device)\n",
    "        matches1_2 = matches1_2.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predicted_points = model(affine_params, matches1)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(predicted_points, matches1_2)\n",
    "\n",
    "        val_running_loss += loss.item()\n",
    "        test_bar.set_postfix({'loss': val_running_loss / (i+1)})\n",
    "\n",
    "    val_loss_list.append(val_running_loss / len(test_dataset_new))\n",
    "    # if epoch % 10 == 0:\n",
    "    #     print(f'Epoch [{epoch + 1}/{epochs}], Val Loss: {val_running_loss / len(test_dataset_new)}')\n",
    "\n",
    "    # Save the model if the validation loss is the lowest we've seen so far\n",
    "    # if val_loss_list[-1] == min(val_loss_list):\n",
    "    #     torch.save(model.state_dict(), f'trained_models/affine_NN_{epoch:03d}.pth')\n",
    "    #     print('Model saved')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to file train_model/affine_transformation_network.pt\n",
    "torch.save(model.state_dict(), f'trained_models/affine_NN_{num_hidden_layers}_{num_perceptrons}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), epoch_loss_list, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning Train Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loss_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRunning Validation Loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "File \u001b[0;32m~/miniconda3/envs/spppt/lib/python3.8/site-packages/matplotlib/pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/spppt/lib/python3.8/site-packages/matplotlib/axes/_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/miniconda3/envs/spppt/lib/python3.8/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/spppt/lib/python3.8/site-packages/matplotlib/axes/_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Plot train loss and validation loss against epoch number\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, epochs+1), epoch_loss_list, label='Running Train Loss', linewidth=3)\n",
    "plt.plot(range(1, epochs+1), val_loss_list, label='Running Validation Loss', linewidth=3)\n",
    "plt.title('Train Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "# plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "# signaturebar_gray(fig, f'{model_params.get_model_code()} - epoch{model_params.num_epochs} - {timestamp}')\n",
    "# fig.savefig(save_plot_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   3%|▎         | 11/400 [00:00<00:03, 122.31it/s, loss=3.01e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 79.0, Predicted: 78.56182861328125\n",
      "True: 98.0, Predicted: 93.4625244140625\n",
      "True: 221.0, Predicted: 203.40243530273438\n",
      "True: 72.0, Predicted: 72.2575454711914\n",
      "True: 23.0, Predicted: 50.942466735839844\n",
      "True: 212.0, Predicted: 241.40090942382812\n",
      "True: 10.0, Predicted: 37.490238189697266\n",
      "True: 205.0, Predicted: 232.00682067871094\n",
      "True: 113.0, Predicted: 140.51112365722656\n",
      "True: 165.0, Predicted: 197.4630584716797\n",
      "True: 36.0, Predicted: 54.7857780456543\n",
      "True: 19.0, Predicted: 41.7234992980957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_loss_list = []\n",
    "test_bar = tqdm(test_dataset_new, desc='Testing')\n",
    "for i, (input, matches1_2) in enumerate(test_bar):\n",
    "    # Set the inputs and labels to the training device\n",
    "    # source_img = source_img.to(device)\n",
    "    # target_img = target_img.to(device)\n",
    "    affine_params = input[:6].to(device)\n",
    "    matches1 = input[6:].to(device)\n",
    "    # matches2 = matches2.to(device)\n",
    "    matches1_2 = matches1_2.to(device)\n",
    "\n",
    "    # optimizer.zero_grad()\n",
    "    # for j in range(matches1.shape[1]):\n",
    "    # Forward pass\n",
    "    predicted_points = model(affine_params, matches1)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(predicted_points, matches1_2)\n",
    "\n",
    "    test_loss_list += loss.item()\n",
    "\n",
    "    test_bar.set_postfix({'loss': running_loss / (i+1)})\n",
    "    print(f'True: {matches1_2[0]}, Predicted: {predicted_points[0]}')\n",
    "    if i > 10:\n",
    "        break\n",
    "\n",
    "# mean and std of the test loss\n",
    "mean_test_loss = np.mean(test_loss_list)\n",
    "std_test_loss = np.std(test_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage after training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sample_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m      3\u001b[0m transformed_point \u001b[38;5;241m=\u001b[39m model(sample_input[\u001b[38;5;241m2\u001b[39m], sample_input[\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformed Point:\u001b[39m\u001b[38;5;124m\"\u001b[39m, transformed_point)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# Example usage after training\n",
    "sample_input = list(test_dataset)[0].to(device)\n",
    "transformed_point = model(sample_input[2], sample_input[3])\n",
    "print(\"Transformed Point:\", transformed_point)\n",
    "print(\"Ground Truth:\", sample_input[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spppt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
