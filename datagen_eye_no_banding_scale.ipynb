{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "(5040, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>Source ROI</th>\n",
       "      <th>target</th>\n",
       "      <th>Target ROI</th>\n",
       "      <th>training</th>\n",
       "      <th>Warped target images</th>\n",
       "      <th>Warped target ROI</th>\n",
       "      <th>Execution time</th>\n",
       "      <th>Directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011248_20161215__L_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_b1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011248_20161215__L_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_b3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011248_20161215__L_b1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_b3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       source  Source ROI                      target  \\\n",
       "0  2011248_20161215__L_b2.jpg         NaN  2011248_20161215__L_b1.jpg   \n",
       "1  2011248_20161215__L_b2.jpg         NaN  2011248_20161215__L_b3.jpg   \n",
       "2  2011248_20161215__L_b1.jpg         NaN  2011248_20161215__L_b3.jpg   \n",
       "3  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c1.jpg   \n",
       "4  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c3.jpg   \n",
       "\n",
       "   Target ROI  training  Warped target images  Warped target ROI  \\\n",
       "0         NaN         1                   NaN                NaN   \n",
       "1         NaN         1                   NaN                NaN   \n",
       "2         NaN         1                   NaN                NaN   \n",
       "3         NaN         0                   NaN                NaN   \n",
       "4         NaN         0                   NaN                NaN   \n",
       "\n",
       "   Execution time                                        Directory  \n",
       "0             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lb  \n",
       "1             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lb  \n",
       "2             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lb  \n",
       "3             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lc  \n",
       "4             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lc  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the file 'dataset_reg_pair_filled.csv' and generate synthetic data\n",
    "# first read the file, then make a list of the source training images\n",
    "# then for each image, generate 10 synthetic images with random affine transformation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils.utils0 import tensor_affine_transform, transform_to_displacement_field\n",
    "from utils.utils1 import transform_points_DVF\n",
    "from utils.SuperPoint import SuperPointFrontend, PointTracker\n",
    "superpoint = SuperPointFrontend('utils/superpoint_v1.pth', nms_dist=4,\n",
    "                          conf_thresh=0.015, nn_thresh=0.7, cuda=True)\n",
    "\n",
    "# read the file\n",
    "df = pd.read_csv('Dataset/dataset_reg_pair_filled.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2286792/1623562252.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['image_path'] = df_train['Directory'] + '/' + df_train['source']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>Source ROI</th>\n",
       "      <th>target</th>\n",
       "      <th>Target ROI</th>\n",
       "      <th>training</th>\n",
       "      <th>Warped target images</th>\n",
       "      <th>Warped target ROI</th>\n",
       "      <th>Execution time</th>\n",
       "      <th>Directory</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011248_20161215__L_c1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011248_20161215__R_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__R_b3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Rb</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011248_20161215__R_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__R_b1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Rb</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       source  Source ROI                      target  \\\n",
       "3  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c1.jpg   \n",
       "4  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c3.jpg   \n",
       "5  2011248_20161215__L_c1.jpg         NaN  2011248_20161215__L_c3.jpg   \n",
       "6  2011248_20161215__R_b2.jpg         NaN  2011248_20161215__R_b3.jpg   \n",
       "7  2011248_20161215__R_b2.jpg         NaN  2011248_20161215__R_b1.jpg   \n",
       "\n",
       "   Target ROI  training  Warped target images  Warped target ROI  \\\n",
       "3         NaN         0                   NaN                NaN   \n",
       "4         NaN         0                   NaN                NaN   \n",
       "5         NaN         0                   NaN                NaN   \n",
       "6         NaN         0                   NaN                NaN   \n",
       "7         NaN         0                   NaN                NaN   \n",
       "\n",
       "   Execution time                                        Directory  \\\n",
       "3             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lc   \n",
       "4             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lc   \n",
       "5             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lc   \n",
       "6             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Rb   \n",
       "7             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Rb   \n",
       "\n",
       "                                          image_path  \n",
       "3  Dataset/Dataset-processed/15-12-2559/2011248/L...  \n",
       "4  Dataset/Dataset-processed/15-12-2559/2011248/L...  \n",
       "5  Dataset/Dataset-processed/15-12-2559/2011248/L...  \n",
       "6  Dataset/Dataset-processed/15-12-2559/2011248/R...  \n",
       "7  Dataset/Dataset-processed/15-12-2559/2011248/R...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a list of the unique source training images that has 'training' = 0\n",
    "# each image path consists of image directory, image name\n",
    "\n",
    "df_train = df[df['training'] == 0]\n",
    "\n",
    "# create a new df consists of image directory and image name concatenated\n",
    "df_train['image_path'] = df_train['Directory'] + '/' + df_train['source']\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4132, 10)\n",
      "500\n",
      "Dataset/Dataset-processed/15-12-2559/2011248/Lc/2011248_20161215__L_c2.jpg\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "# make a list of the unique values in the column 'image_path'\n",
    "image_list = df_train['image_path'].unique()[:500]\n",
    "print(len(image_list))\n",
    "print(image_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_translation = 0.1  # Minimum translation in pixels\n",
    "max_translation = 0.2  # Maximum translation in pixels\n",
    "max_rotation = 10  # Maximum rotation in degrees\n",
    "max_shear = 10  # Maximum shear in degrees\n",
    "min_scale = 0.85  # Minimum scale factor\n",
    "max_scale = 1.15  # Maximum scale factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply only scaling to the eye images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_affine_transformed_images_multiple(img_list, csv_file, output_dir, num_images=5, modify=False):\n",
    "    # delete all files and subdirectories in the output directory\n",
    "    shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # create a list to store different point locations\n",
    "    points_list = []\n",
    "\n",
    "    # Initialize the CSV file with a header\n",
    "    with open(csv_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"source\", \"target\", \"M00\", \"M01\", \"M02\", \"M10\", \"M11\", \"M12\", \"image_path\", \"keypoints\"])\n",
    "\n",
    "    # Loop over the images, read the image, \n",
    "    # apply affine transformation and save it\n",
    "    for i, img_path in enumerate(img_list):\n",
    "        # if i > len(img_list)/2:\n",
    "        #     break\n",
    "        # Read the image as grayscale using cv2\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Save original image\n",
    "        original_image_path = os.path.join(output_dir, f\"img_{i}_original.png\")\n",
    "\n",
    "        # take 90% of the image\n",
    "        image_base = image[int(image.shape[0]*0.05):int(image.shape[0]*0.95), int(image.shape[1]*0.05):int(image.shape[1]*0.95)]\n",
    "        # resize image to 256x256\n",
    "        image_base = cv2.resize(image_base, (256, 256))\n",
    "\n",
    "        cv2.imwrite(original_image_path, image_base + np.random.uniform(-0.01, 0.01, image_base.shape))\n",
    "\n",
    "        # Convert the transformed image to a numpy array\n",
    "        # img_transformed = np.array(img_transformed)\n",
    "        image_base = np.array(Image.fromarray(image_base).convert('L'))\n",
    "\n",
    "        tracker = PointTracker(5, nn_thresh=0.7)\n",
    "        points1, desc1, _ = superpoint(image_base.astype(np.float32)/255)\n",
    "\n",
    "        for j in range(num_images):\n",
    "            # random (2x3) affine transformation matrix\n",
    "            #M = np.array([[1.0, 0.0, np.random()], [0.0, 1.0, 0.0]])\n",
    "            if j == num_images-1:\n",
    "                img_transformed = image_base\n",
    "                M = np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]])\n",
    "                points2 = points1.copy()\n",
    "                desc2 = desc1.copy()\n",
    "                # matches = tracker.nn_match_two_way(desc1, desc2, nn_thresh=0.7)\n",
    "                # matches1 = points1[:2, matches[0, :].astype(int)]\n",
    "                # matches2 = matches1\n",
    "                # matches1_transformed_DVF = matches1\n",
    "                # points_list.append(matches1_transformed_DVF[:, 0] - matches2[:, 0])\n",
    "\n",
    "                # random (2x3) affine transformation matrix\n",
    "                # M = np.array([[1.0, 0.0, np.random()], [0.0, 1.0, 0.0]])\n",
    "                # rand_range = 0.2\n",
    "                # test_random = np.random.uniform(-rand_range, rand_range, 2)\n",
    "                # M = np.array([[1.0, 0.0, test_random[0]], [0.0, 1.0, test_random[1]]])\n",
    "\n",
    "                # random (2x3) affine transformation matrix\n",
    "                # random only translation and scale\n",
    "                # M = np.array([[1.0 + np.random.uniform(-0.2, 0.2), 0.0, np.random.uniform(-0.2, 0.2)], \n",
    "                #               [0.0, 1.0 + np.random.uniform(-0.2, 0.2), np.random.uniform(-0.2, 0.2)]])\n",
    "            \n",
    "            else:\n",
    "                rand_range = 0.1\n",
    "                test_random = [np.random.uniform(-3*rand_range, rand_range), np.random.uniform(-1.5*rand_range, rand_range)]\n",
    "                # M = np.array([[1.0 + test_random[0], 0.0, 0.0], [0.0, 1.0 + test_random[1], 0.0]])\n",
    "                M = np.array([[1.0 + test_random[0], 0.0, 0.0], [0.0, 1.0 + test_random[1], 0.0]])\n",
    "\n",
    "                # calculate the pixel coverage of the translation\n",
    "                # print(f'Img {i}, translation: {test_random[0]*image.shape[1]}, {test_random[1]*image.shape[0]}')\n",
    "\n",
    "                # image pixel shifted from image_base TODO: the random translation must not exceed the image_base\n",
    "                # x_shift_1 = int(image.shape[1]*0.05) + int(test_random[0]*image.shape[1])\n",
    "                # x_shift_2 = int(image.shape[1]*0.95) + int(test_random[0]*image.shape[1])\n",
    "                # y_shift_1 = int(image.shape[0]*0.05) + int(test_random[1]*image.shape[0])\n",
    "                # y_shift_2 = int(image.shape[0]*0.95) + int(test_random[1]*image.shape[0])\n",
    "                # img_transformed = image[y_shift_1:y_shift_2, x_shift_1:x_shift_2]\n",
    "                # print(img_transformed.shape)\n",
    "\n",
    "                img_transformed = tensor_affine_transform(torch.tensor(image).unsqueeze(0).unsqueeze(0).float(), torch.tensor(M).unsqueeze(0).float())\n",
    "                img_transformed = img_transformed.squeeze(0).squeeze(0).numpy()\n",
    "                img_transformed = img_transformed[int(image.shape[0]*0.05):int(image.shape[0]*0.95), int(image.shape[1]*0.05):int(image.shape[1]*0.95)]\n",
    "\n",
    "            # resize image to 256x256\n",
    "            img_transformed = cv2.resize(img_transformed, (256, 256))\n",
    "            # convert to grayscale\n",
    "            img_transformed_BW = np.array(Image.fromarray(img_transformed).convert('L'))\n",
    "\n",
    "            # # TODO: save heatmaps for other version of network\n",
    "            points2, desc2, _ = superpoint(img_transformed_BW.astype(np.float32)/255)\n",
    "            matches = tracker.nn_match_two_way(desc1, desc2, nn_thresh=0.7)\n",
    "\n",
    "            # # print(desc1.shape, desc2.shape)\n",
    "            matches1 = points1[:2, matches[0, :].astype(int)]\n",
    "            # # matches1 = matches1.T[None, :, :]\n",
    "            matches2 = points2[:2, matches[1, :].astype(int)]\n",
    "            \n",
    "            # transform the points using the displacement field\n",
    "            # print(torch.tensor(M)[None, :, :].shape, torch.tensor(image)[None, None, :, :].shape)\n",
    "            # print(torch.tensor(M).shape, torch.tensor(image).shape, torch.tensor(matches1.copy()).unsqueeze(-1).view(2, -1, 1).shape)\n",
    "            matches1_transformed_DVF = transform_points_DVF(torch.tensor(matches1.copy()).unsqueeze(-1).view(2, -1, 1), \n",
    "                torch.tensor(M).view(1, 2, 3), torch.tensor(image_base).unsqueeze(0).unsqueeze(0))\n",
    "            # print(f'Img {i}, diff: {matches1_transformed_DVF[:, 0] - matches2[:, 0]}')\n",
    "            # points_list.append(matches1_transformed_DVF[:, 0] - matches2[:, 0])\n",
    "\n",
    "            # add some noise to the transformed image and save it\n",
    "            img_transformed = img_transformed + np.random.uniform(-0.01, 0.01, img_transformed.shape)\n",
    "            if modify: # if modify is True, then add some intensity change to the transformed image\n",
    "                img_transformed = img_transformed + np.random.normal(1, 0.1, 1)\n",
    "\n",
    "\n",
    "            transformed_image_path = os.path.join(output_dir, f\"img_{i}_transformed_{j}.png\")\n",
    "            cv2.imwrite(transformed_image_path, img_transformed)\n",
    "\n",
    "            # create a dataframe with the matches\n",
    "            # print(matches1.shape, matches2.shape, matches1_transformed_DVF.shape)\n",
    "            if len(matches1_transformed_DVF.shape) == 3:\n",
    "                matches1_transformed_DVF = matches1_transformed_DVF.squeeze(-1)\n",
    "            df = pd.DataFrame({'x1': matches1[0, :], 'y1': matches1[1, :],\n",
    "                            'x2': matches2[0, :], 'y2': matches2[1, :],\n",
    "                            'x2_': matches1_transformed_DVF[0, :], 'y2_': matches1_transformed_DVF[1, :]})\n",
    "            save_name = os.path.join(output_dir, f\"img_{i}_{j}_keypoints.csv\")\n",
    "            df.to_csv(save_name, index=False)\n",
    "\n",
    "            with open(csv_file, 'a', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow([original_image_path, transformed_image_path, \n",
    "                                M[0, 0], M[0, 1], M[0, 2], M[1, 0], M[1, 1], M[1, 2], img_path, save_name])\n",
    "\n",
    "\n",
    "    print(f\"\\nGenerated {(i + 1)*num_images} images\")\n",
    "    # print mean absolute error of the points\n",
    "    # print('MAE point location error:', np.mean(np.abs(np.array(points_list))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train data generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pakpoom/codes/spppt-2/.venv/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated 10000 images\n"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "output_dir = \"Dataset/synth_eye_medium_train_scaling\"  # Output directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# plot_dir = \"Dataset/synthetic_eye_dataset_train/plot\"\n",
    "# os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# generate synthetic images for each source training image\n",
    "generate_affine_transformed_images_multiple(image_list,\n",
    "    'Dataset/synth_eye_medium_train_scaling.csv', output_dir, num_images=20, modify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameters\n",
    "# image_size = (512, 512)  # Size of the images\n",
    "# output_dir = \"Dataset/synthetic_eye_dataset_train_multiple\"  # Output directory\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # plot_dir = \"Dataset/synthetic_eye_dataset_train_multiple/plot\"\n",
    "# # os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# # generate synthetic images for each source training image\n",
    "# generate_affine_transformed_images_multiple(image_list,'dataset_eye_synth_train_multiple.csv', output_dir, num_images=2, modify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2286792/2538931727.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['image_path'] = df_test['Directory'] + '/' + df_test['source']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(908, 10)\n",
      "\n",
      "Generated 200 images\n"
     ]
    }
   ],
   "source": [
    "# do the same for the test images\n",
    "df_test = df[df['training'] == 1]\n",
    "df_test['image_path'] = df_test['Directory'] + '/' + df_test['source']\n",
    "print(df_test.shape)\n",
    "image_list_test = df_test['image_path'].unique()[:100]\n",
    "\n",
    "# Define parameters\n",
    "output_dir = \"Dataset/synth_eye_medium_test\"  # Output directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# plot_dir = \"Dataset/synthetic_eye_dataset_test/plot\"\n",
    "# os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# generate synthetic images for each source test image\n",
    "generate_affine_transformed_images_multiple(image_list_test, 'Dataset/synth_eye_medium_test.csv', \n",
    "                                            output_dir, num_images=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameters\n",
    "# image_size = (512, 512)  # Size of the images\n",
    "# output_dir = \"Dataset/synthetic_eye_dataset_test_multiple\"  # Output directory\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # plot_dir = \"Dataset/synthetic_eye_dataset_test/plot\"\n",
    "# # os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# # generate synthetic images for each source test image\n",
    "# generate_affine_transformed_images_multiple(image_list_test, 'dataset_eye_synth_test_scaling.csv', output_dir, num_images=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spppt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
