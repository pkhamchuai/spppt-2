{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5040, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>Source ROI</th>\n",
       "      <th>target</th>\n",
       "      <th>Target ROI</th>\n",
       "      <th>training</th>\n",
       "      <th>Warped target images</th>\n",
       "      <th>Warped target ROI</th>\n",
       "      <th>Execution time</th>\n",
       "      <th>Directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011248_20161215__L_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_b1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011248_20161215__L_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_b3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011248_20161215__L_b1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_b3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       source  Source ROI                      target  \\\n",
       "0  2011248_20161215__L_b2.jpg         NaN  2011248_20161215__L_b1.jpg   \n",
       "1  2011248_20161215__L_b2.jpg         NaN  2011248_20161215__L_b3.jpg   \n",
       "2  2011248_20161215__L_b1.jpg         NaN  2011248_20161215__L_b3.jpg   \n",
       "3  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c1.jpg   \n",
       "4  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c3.jpg   \n",
       "\n",
       "   Target ROI  training  Warped target images  Warped target ROI  \\\n",
       "0         NaN         1                   NaN                NaN   \n",
       "1         NaN         1                   NaN                NaN   \n",
       "2         NaN         1                   NaN                NaN   \n",
       "3         NaN         0                   NaN                NaN   \n",
       "4         NaN         0                   NaN                NaN   \n",
       "\n",
       "   Execution time                                        Directory  \n",
       "0             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lb  \n",
       "1             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lb  \n",
       "2             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lb  \n",
       "3             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lc  \n",
       "4             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lc  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the file 'dataset_reg_pair_filled.csv' and generate synthetic data\n",
    "# first read the file, then make a list of the source training images\n",
    "# then for each image, generate 10 synthetic images with random affine transformation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "from utils.utils0 import tensor_affine_transform, transform_to_displacement_field\n",
    "from utils.utils1 import transform_points_DVF, transform_points_from_DVF_unbatched, transform_points_from_DVF, plot_grid\n",
    "from utils.SuperPoint import SuperPointFrontend, PointTracker\n",
    "superpoint = SuperPointFrontend('utils/superpoint_v1.pth', nms_dist=4,\n",
    "                          conf_thresh=0.015, nn_thresh=0.7, cuda=True)\n",
    "\n",
    "# read the file\n",
    "df = pd.read_csv('Dataset/dataset_reg_pair_filled.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12002/1623562252.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['image_path'] = df_train['Directory'] + '/' + df_train['source']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>Source ROI</th>\n",
       "      <th>target</th>\n",
       "      <th>Target ROI</th>\n",
       "      <th>training</th>\n",
       "      <th>Warped target images</th>\n",
       "      <th>Warped target ROI</th>\n",
       "      <th>Execution time</th>\n",
       "      <th>Directory</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011248_20161215__L_c1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011248_20161215__R_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__R_b3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Rb</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011248_20161215__R_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__R_b1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Rb</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       source  Source ROI                      target  \\\n",
       "3  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c1.jpg   \n",
       "4  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c3.jpg   \n",
       "5  2011248_20161215__L_c1.jpg         NaN  2011248_20161215__L_c3.jpg   \n",
       "6  2011248_20161215__R_b2.jpg         NaN  2011248_20161215__R_b3.jpg   \n",
       "7  2011248_20161215__R_b2.jpg         NaN  2011248_20161215__R_b1.jpg   \n",
       "\n",
       "   Target ROI  training  Warped target images  Warped target ROI  \\\n",
       "3         NaN         0                   NaN                NaN   \n",
       "4         NaN         0                   NaN                NaN   \n",
       "5         NaN         0                   NaN                NaN   \n",
       "6         NaN         0                   NaN                NaN   \n",
       "7         NaN         0                   NaN                NaN   \n",
       "\n",
       "   Execution time                                        Directory  \\\n",
       "3             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lc   \n",
       "4             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lc   \n",
       "5             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lc   \n",
       "6             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Rb   \n",
       "7             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Rb   \n",
       "\n",
       "                                          image_path  \n",
       "3  Dataset/Dataset-processed/15-12-2559/2011248/L...  \n",
       "4  Dataset/Dataset-processed/15-12-2559/2011248/L...  \n",
       "5  Dataset/Dataset-processed/15-12-2559/2011248/L...  \n",
       "6  Dataset/Dataset-processed/15-12-2559/2011248/R...  \n",
       "7  Dataset/Dataset-processed/15-12-2559/2011248/R...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a list of the unique source training images that has 'training' = 0\n",
    "# each image path consists of image directory, image name\n",
    "\n",
    "df_train = df[df['training'] == 0]\n",
    "\n",
    "# create a new df consists of image directory and image name concatenated\n",
    "df_train['image_path'] = df_train['Directory'] + '/' + df_train['source']\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4132, 10)\n",
      "50\n",
      "Dataset/Dataset-processed/15-12-2559/2011248/Lc/2011248_20161215__L_c2.jpg\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "# make a list of the unique values in the column 'image_path'\n",
    "image_list = df_train['image_path'].unique()[:50]\n",
    "print(len(image_list))\n",
    "print(image_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_translation = 0.1  # Minimum translation in pixels\n",
    "max_translation = 0.2  # Maximum translation in pixels\n",
    "max_rotation = 20  # Maximum rotation in degrees\n",
    "max_shear = 10  # Maximum shear in degrees\n",
    "min_scale = 0.85  # Minimum scale factor\n",
    "max_scale = 1.15  # Maximum scale factor\n",
    "max_perspective = 0.1  # Maximum perspective distortion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_csv('Dataset/synth_eye_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.to_csv('Dataset/synth_eye_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: a fuction for warping image using perspective transformation\n",
    "def warp_image_perspective_cv2(image, M):\n",
    "    # image: a numpy array of shape (H, W, 3)\n",
    "    # M: a numpy array of shape (3, 3)\n",
    "    # return: a numpy array of shape (H, W, 3)\n",
    "    H, W, _ = image.shape\n",
    "    warped_image = cv2.warpPerspective(image, M, (W, H))\n",
    "    return warped_image\n",
    "\n",
    "def warp_image_perspective_pytorch(image, M):\n",
    "    '''\n",
    "    - Grid Generation: We generate a grid of coordinates (x, y) for the image.\n",
    "    - Homography Application: We apply the homography matrix M to these coordinates to get transformed coordinates.\n",
    "    - Grid Sampling: We then use grid_sample to sample the image at these transformed coordinates.\n",
    "    '''\n",
    "\n",
    "    H, W = image.shape\n",
    "    M = torch.from_numpy(M).float()\n",
    "\n",
    "    # Generate a grid of coordinates (x, y) for the image\n",
    "    y, x = torch.meshgrid(torch.arange(H), torch.arange(W))\n",
    "    ones = torch.ones_like(x)\n",
    "    \n",
    "    x_transformed = (M[0, 0]*x + M[0, 1]*x + M[0, 1]*x)/(M[2, 0]*x + M[2, 1]*x + 1)\n",
    "    y_transformed = (M[1, 0]*y + M[1, 1]*y + M[1, 1]*y)/(M[2, 0]*y + M[2, 1]*y + 1)\n",
    "    transformed_grid = torch.stack([x, y], dim=-1).float()\n",
    "\n",
    "    # grid = torch.stack([x, y, ones], dim=-1).float()  # Shape (H, W, 3)\n",
    "    \n",
    "    # # Flatten the grid to (H*W, 3)\n",
    "    # grid_flat = grid.view(-1, 3).t()  # Shape (3, H*W)\n",
    "    \n",
    "    # # Apply the homography transformation\n",
    "    # # transformed_grid = M @ grid_flat  # Shape (3, H*W)\n",
    "\n",
    "    \n",
    "    # # Convert from homogeneous to Cartesian coordinates\n",
    "    # transformed_grid = transformed_grid / transformed_grid[2, :]\n",
    "    # transformed_grid = transformed_grid[:2, :].t()  # Shape (H*W, 2)\n",
    "    \n",
    "    # Reshape the transformed coordinates to the original image shape\n",
    "    transformed_grid_ = transformed_grid.view(H, W, 2).clone()\n",
    "    transformed_grid = transformed_grid.view(H, W, 2)\n",
    "    \n",
    "    # Normalize coordinates to be in range [-1, 1] for grid_sample\n",
    "    transformed_grid[..., 0] = (transformed_grid[..., 0] / (W - 1)) * 2 - 1\n",
    "    transformed_grid[..., 1] = (transformed_grid[..., 1] / (H - 1)) * 2 - 1\n",
    "    \n",
    "    # Add batch dimension and channel dimension, permute to (_, H, W, 1)\n",
    "    transformed_grid = transformed_grid.unsqueeze(0)\n",
    "    \n",
    "    if len(image.shape) == 2:\n",
    "        image = torch.from_numpy(image).float().unsqueeze(0).unsqueeze(0)\n",
    "    # image = image.permute(2, 0, 1).unsqueeze(0)\n",
    "    \n",
    "    # Sample the image using the transformed grid\n",
    "    warped_image = torch.nn.functional.grid_sample(image, transformed_grid, align_corners=False)\n",
    "    \n",
    "    # Remove batch and channel dimensions and convert to numpy\n",
    "    # warped_image = warped_image.squeeze(0).squeeze(0).numpy()\n",
    "    \n",
    "    return warped_image, transformed_grid_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply all transformations to the eye images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_transformed_points(width, height, affine_params, perspective_params):\n",
    "#     \"\"\"\n",
    "#     Calculate the transformed points based on affine and perspective parameters.\n",
    "#     :param width: Image width\n",
    "#     :param height: Image height\n",
    "#     :param affine_params: A list of 6 affine transformation parameters [a, b, c, d, e, f]\n",
    "#     :param perspective_params: A list of 2 perspective transformation parameters [p1, p2]\n",
    "#     :return: Start points and transformed end points\n",
    "#     \"\"\"\n",
    "#     # Original corner points of the image\n",
    "#     startpoints = np.array([[0, 0], [width, 0], [width, height], [0, height]], dtype=np.float32)\n",
    "\n",
    "#     # Create the affine transformation matrix\n",
    "#     a, b, c, d, e, f = affine_params\n",
    "#     M_affine = np.array([\n",
    "#         [a, b, c],\n",
    "#         [d, e, f],\n",
    "#         [0, 0, 1]\n",
    "#     ], dtype=np.float32)\n",
    "\n",
    "#     # Create the perspective transformation matrix\n",
    "#     p1, p2 = perspective_params\n",
    "#     M_perspective = np.array([\n",
    "#         [1, 0, 0],\n",
    "#         [0, 1, 0],\n",
    "#         [p1, p2, 1]\n",
    "#     ], dtype=np.float32)\n",
    "\n",
    "#     # Combine the affine and perspective transformations\n",
    "#     M_combined = np.dot(M_perspective, M_affine)\n",
    "\n",
    "#     # Transform the corner points using the combined matrix\n",
    "#     endpoints = []\n",
    "#     for point in startpoints:\n",
    "#         transformed_point = np.dot(M_combined, [point[0], point[1], 1])\n",
    "#         transformed_point /= transformed_point[2]  # Normalize the homogeneous coordinate\n",
    "#         endpoints.append(transformed_point[:2])\n",
    "    \n",
    "#     return startpoints.tolist(), endpoints, M_combined\n",
    "\n",
    "# def apply_perspective_transform(image, startpoints, endpoints):\n",
    "#     \"\"\"\n",
    "#     Apply the perspective transformation using the calculated start and end points.\n",
    "#     \"\"\"\n",
    "#     # if the image is not a PIL image, convert it to a PIL image\n",
    "#     if not isinstance(image, Image.Image):\n",
    "#         image = Image.fromarray(image)\n",
    "#     transformed_image = F.perspective(image, startpoints, endpoints, interpolation=Image.BICUBIC)\n",
    "#     return transformed_image\n",
    "\n",
    "# # Load your image\n",
    "# image = Image.open('path_to_your_image.jpg')\n",
    "\n",
    "# # Define the 6 affine parameters (rotation, scaling, translation, etc.)\n",
    "# affine_params = [1, 0, 0, 0, 1, 0]  # Identity transform for simplicity (no affine change)\n",
    "\n",
    "# # Define the 2 perspective parameters\n",
    "# perspective_params = [0.001, 0.001]  # Small perspective distortion\n",
    "\n",
    "# # Calculate the transformed points\n",
    "# width, height = image.size\n",
    "# startpoints, endpoints = calculate_transformed_points(width, height, affine_params, perspective_params)\n",
    "\n",
    "# # Apply the perspective transformation\n",
    "# warped_image = apply_perspective_transform(image, startpoints, endpoints)\n",
    "\n",
    "# # Display the transformed image\n",
    "# warped_image.show()\n",
    "\n",
    "# # Print the start and end points\n",
    "# print(\"Start Points:\\n\", startpoints)\n",
    "# print(\"End Points:\\n\", endpoints)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def calculate_endpoints(width, height, params):\n",
    "    \"\"\"\n",
    "    Calculate the four endpoints for the perspective transformation given\n",
    "    affine and perspective parameters.\n",
    "    \"\"\"\n",
    "    h11, h12, h13, h21, h22, h23, h31, h32, _ = params\n",
    "\n",
    "    # Corners of the original image\n",
    "    topleft = np.array([0, 0, 1])\n",
    "    topright = np.array([width, 0, 1])\n",
    "    bottomright = np.array([width, height, 1])\n",
    "    bottomleft = np.array([0, height, 1])\n",
    "\n",
    "    # Create the perspective transformation matrix H\n",
    "    H = np.array([\n",
    "        [h11, h12, h13],\n",
    "        [h21, h22, h23],\n",
    "        [h31, h32, 1]\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    # Apply the transformation to each corner\n",
    "    topleft_transformed = np.dot(H, topleft)\n",
    "    topright_transformed = np.dot(H, topright)\n",
    "    bottomright_transformed = np.dot(H, bottomright)\n",
    "    bottomleft_transformed = np.dot(H, bottomleft)\n",
    "\n",
    "    # Normalize to Cartesian coordinates\n",
    "    topleft_transformed /= topleft_transformed[2]\n",
    "    topright_transformed /= topright_transformed[2]\n",
    "    bottomright_transformed /= bottomright_transformed[2]\n",
    "    bottomleft_transformed /= bottomleft_transformed[2]\n",
    "\n",
    "    # Extract (x, y) coordinates\n",
    "    startpoints = [[0, 0], [width, 0], [width, height], [0, height]]\n",
    "    endpoints = [\n",
    "        topleft_transformed[:2].tolist(),\n",
    "        topright_transformed[:2].tolist(),\n",
    "        bottomright_transformed[:2].tolist(),\n",
    "        bottomleft_transformed[:2].tolist()\n",
    "    ]\n",
    "\n",
    "    return startpoints, endpoints\n",
    "\n",
    "def get_random_perspective_params(width, height, distortion_scale):\n",
    "    \"\"\"\n",
    "    Generate random offsets for the four corners to create a perspective warp.\n",
    "    \"\"\"\n",
    "    topleft = (random.uniform(0, distortion_scale) * width, random.uniform(0, distortion_scale) * height)\n",
    "    topright = (random.uniform(1 - distortion_scale, 1) * width, random.uniform(0, distortion_scale) * height)\n",
    "    botright = (random.uniform(1 - distortion_scale, 1) * width, random.uniform(1 - distortion_scale, 1) * height)\n",
    "    botleft = (random.uniform(0, distortion_scale) * width, random.uniform(1 - distortion_scale, 1) * height)\n",
    "\n",
    "    startpoints = [[0, 0], [width, 0], [width, height], [0, height]]\n",
    "    endpoints = [topleft, topright, botright, botleft]\n",
    "    return startpoints, endpoints\n",
    "\n",
    "def calculate_perspective_matrix(startpoints, endpoints):\n",
    "    \"\"\"\n",
    "    Calculate the perspective transformation matrix from start and end points.\n",
    "    \"\"\"\n",
    "    startpoints = torch.tensor(startpoints, dtype=torch.float32)\n",
    "    endpoints = torch.tensor(endpoints, dtype=torch.float32)\n",
    "    \n",
    "    # Solve the linear system to find the perspective transformation matrix\n",
    "    A = []\n",
    "    for (x, y), (u, v) in zip(startpoints, endpoints):\n",
    "        A.append([-x, -y, -1, 0, 0, 0, x*u, y*u, u])\n",
    "        A.append([0, 0, 0, -x, -y, -1, x*v, y*v, v])\n",
    "    A = torch.tensor(A, dtype=torch.float32)\n",
    "    _, _, V = torch.svd(A)\n",
    "    H = V[:, -1].reshape(3, 3)\n",
    "    return H\n",
    "\n",
    "# def apply_perspective_transform(image, perspective_matrix):\n",
    "#     \"\"\"\n",
    "#     Apply the perspective transformation using the provided matrix.\n",
    "#     \"\"\"\n",
    "#     width, height = image.shape[1], image.shape[0]\n",
    "#     # Create a meshgrid for the image coordinates\n",
    "#     y, x = torch.meshgrid(torch.arange(height), torch.arange(width))\n",
    "#     xy1 = torch.stack([x.flatten(), y.flatten(), torch.ones_like(x.flatten())], dim=0)  # Shape (3, H*W)\n",
    "\n",
    "#     # Apply the perspective transformation\n",
    "#     transformed_xy1 = torch.matmul(perspective_matrix, xy1)\n",
    "#     transformed_xy1 = transformed_xy1[:2] / transformed_xy1[2]  # Normalize by the third coordinate\n",
    "#     transformed_xy1 = transformed_xy1.view(2, height, width).permute(1, 2, 0)  # Shape (H, W, 2)\n",
    "\n",
    "#     # Normalize grid to [-1, 1]\n",
    "#     transformed_xy1[..., 0] = (transformed_xy1[..., 0] / (width - 1)) * 2 - 1\n",
    "#     transformed_xy1[..., 1] = (transformed_xy1[..., 1] / (height - 1)) * 2 - 1\n",
    "\n",
    "#     # Apply the grid sample\n",
    "#     grid = transformed_xy1.unsqueeze(0)\n",
    "#     image_tensor = F.to_tensor(image).unsqueeze(0)\n",
    "#     transformed_image_tensor = F.grid_sample(image_tensor, grid, align_corners=False)\n",
    "#     transformed_image = F.to_pil_image(transformed_image_tensor.squeeze(0))\n",
    "#     return transformed_image\n",
    "\n",
    "def apply_perspective_transform(image, startpoints, endpoints):\n",
    "    \"\"\"\n",
    "    Apply a perspective transformation using calculated start and end points.\n",
    "    \"\"\"\n",
    "    # if the image is not a PIL image, convert it to a PIL image\n",
    "    if not isinstance(image, Image.Image):\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "    image = F.perspective(image, startpoints, endpoints, interpolation=Image.BICUBIC)\n",
    "    \n",
    "    # Calculate the minimum x and y coordinates\n",
    "    min_x = max(0, endpoints[0][0], endpoints[3][0])\n",
    "    min_y = max(0, endpoints[0][1], endpoints[1][1])\n",
    "    \n",
    "    # Calculate the width and height of the cropped image\n",
    "    width = min(256, endpoints[1][0], endpoints[2][0]) - min_x\n",
    "    height = min(256, endpoints[2][1], endpoints[3][1]) - min_y\n",
    "    \n",
    "    print(f\"crop: {min_x}, {min_y}, {width}, {height}\")\n",
    "    # Crop the image\n",
    "    image = image.crop((min_x, min_y, min_x + width, min_y + height))\n",
    "    # print(image.size)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def transform_points(points, H):\n",
    "    \"\"\"\n",
    "    Transform a single point using a homography matrix.\n",
    "    \"\"\"\n",
    "    # if points are not in homogeneous form, convert them\n",
    "    # print(points.shape)\n",
    "    if len(points) == 2:\n",
    "        points = np.array([points[0], points[1], np.ones_like(points[0])], dtype=np.float32)\n",
    "    transformed_point = np.dot(H, points)\n",
    "    transformed_point /= transformed_point[2]\n",
    "    return transformed_point[:2]\n",
    "\n",
    "# Load your image\n",
    "# image = Image.open('path_to_your_image.jpg')\n",
    "\n",
    "# # Define the 8 random parameters for the homography matrix\n",
    "# params = np.random.uniform(-1, 1, size=8)\n",
    "\n",
    "# # Calculate the start and end points\n",
    "# width, height = image.size\n",
    "# startpoints, endpoints = calculate_endpoints(width, height, params)\n",
    "\n",
    "# # Apply the perspective transformation\n",
    "# warped_image = apply_perspective_transform(image, startpoints, endpoints)\n",
    "\n",
    "# # Display the transformed image\n",
    "# warped_image.show()\n",
    "\n",
    "# # Print the start and end points\n",
    "# print(\"Start Points:\\n\", startpoints)\n",
    "# print(\"End Points:\\n\", endpoints)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation function codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_affine_transformed_images_multiple(img_list, csv_file, output_dir, num_images=5, modify=False):\n",
    "    # delete all files and subdirectories in the output directory\n",
    "    shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # create a list to store different point locations\n",
    "    points_list = []\n",
    "\n",
    "    # Initialize the CSV file with a header\n",
    "    with open(csv_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # write the header, perspective parameters, image path, and keypoints\n",
    "        writer.writerow([\"source\", \"target\", \"M01\", \"M02\", \"M03\", \"M04\", \"M05\",\n",
    "            \"M06\", \"M07\", \"M08\", \"M09\",\n",
    "            \"image_path\", \"keypoints\"])\n",
    "\n",
    "    # Loop over the images, read the image, \n",
    "    # apply affine transformation and save it\n",
    "    for i, img_path in enumerate(img_list):\n",
    "        # if i > len(img_list)/2:\n",
    "        #     break\n",
    "        # Read the image as grayscale using cv2\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Save original image\n",
    "        original_image_path = os.path.join(output_dir, f\"img_{i}_original.png\")\n",
    "\n",
    "        # take 90% of the image\n",
    "        image_base = image[int(image.shape[0]*0.1):int(image.shape[0]*0.9), \n",
    "                        int(image.shape[1]*0.1):int(image.shape[1]*0.9)]\n",
    "        # resize image to 256x256\n",
    "        image_base = cv2.resize(image_base, (256, 256))\n",
    "\n",
    "        cv2.imwrite(original_image_path, image_base + np.random.uniform(-0.01, 0.01, image_base.shape))\n",
    "\n",
    "        # Convert the transformed image to a numpy array\n",
    "        # img_transformed = np.array(img_transformed)\n",
    "        image_base = np.array(Image.fromarray(image_base).convert('L'))\n",
    "\n",
    "        tracker = PointTracker(5, nn_thresh=0.7)\n",
    "        points1, desc1, _ = superpoint(image_base.astype(np.float32)/255)\n",
    "\n",
    "        for j in range(num_images):\n",
    "            # random (2x3) affine transformation matrix\n",
    "            #M = np.array([[1.0, 0.0, np.random()], [0.0, 1.0, 0.0]])\n",
    "            if j == num_images-1:\n",
    "                # pass\n",
    "                img_transformed = image_base.copy()\n",
    "                M = np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])\n",
    "                points2 = points1.copy()\n",
    "                desc2 = desc1.copy()\n",
    "                \n",
    "                img_transformed = cv2.resize(img_transformed, (256, 256))\n",
    "                # convert to grayscale\n",
    "                img_transformed_BW = np.array(Image.fromarray(img_transformed).convert('L'))\n",
    "\n",
    "                # # TODO: save heatmaps for other version of network\n",
    "                points2, desc2, _ = superpoint(img_transformed_BW.astype(np.float32)/255)\n",
    "                matches = tracker.nn_match_two_way(desc1, desc2, nn_thresh=0.7)\n",
    "\n",
    "                # # print(desc1.shape, desc2.shape)\n",
    "                matches1 = points1[:2, matches[0, :].astype(int)]\n",
    "                # # matches1 = matches1.T[None, :, :]\n",
    "                matches2 = points2[:2, matches[1, :].astype(int)]\n",
    "                \n",
    "                # transform the points using the displacement field\n",
    "                # print(torch.tensor(M)[None, :, :].shape, torch.tensor(image)[None, None, :, :].shape)\n",
    "                # print(torch.tensor(M).shape, torch.tensor(image).shape, torch.tensor(matches1.copy()).unsqueeze(-1).view(2, -1, 1).shape)\n",
    "                matches1_transformed_DVF = matches1.copy()\n",
    "                # print(f'Img {i}, diff: {matches1_transformed_DVF[:, 0] - matches2[:, 0]}')\n",
    "                # points_list.append(matches1_transformed_DVF[:, 0] - matches2[:, 0])\n",
    "\n",
    "                # add some noise to the transformed image and save it\n",
    "                img_transformed = img_transformed + np.random.uniform(-0.01, 0.01, img_transformed.shape)\n",
    "                if modify: # if modify is True, then add some intensity change to the transformed image\n",
    "                    img_transformed = img_transformed + np.random.normal(1, 0.1, 1)\n",
    "\n",
    "\n",
    "                transformed_image_path = os.path.join(output_dir, f\"img_{i}_transformed_{j}.png\")\n",
    "                cv2.imwrite(transformed_image_path, img_transformed)\n",
    "\n",
    "                # create a dataframe with the matches\n",
    "                # print(matches1.shape, matches2.shape, matches1_transformed_DVF.shape)\n",
    "                if len(matches1_transformed_DVF.shape) == 3:\n",
    "                    matches1_transformed_DVF = matches1_transformed_DVF.squeeze(-1)\n",
    "                df = pd.DataFrame({'x1': matches1[0, :], 'y1': matches1[1, :],\n",
    "                                'x2': matches2[0, :], 'y2': matches2[1, :],\n",
    "                                'x2_': matches1_transformed_DVF[0, :], 'y2_': matches1_transformed_DVF[1, :]})\n",
    "                save_name = os.path.join(output_dir, f\"img_{i}_{j}_keypoints.csv\")\n",
    "                df.to_csv(save_name, index=False)\n",
    "\n",
    "                with open(csv_file, 'a', newline='') as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerow([original_image_path, transformed_image_path, \n",
    "                                    M[0, 0], M[0, 1], M[0, 2], M[1, 0], M[1, 1], M[1, 2], \n",
    "                                    M[2, 0], M[2, 1], M[2, 2], img_path, save_name])\n",
    "            \n",
    "            else:\n",
    "                rand_angle = np.random.uniform(0, max_rotation)/180*np.pi\n",
    "                rand_range = 1.2\n",
    "                scaling = [np.random.uniform(1, rand_range), np.random.uniform(1, rand_range)]\n",
    "                # rand_angle = 10/180*np.pi\n",
    "                translate_range = 0.1\n",
    "                translate = [np.random.uniform(-translate_range, translate_range), np.random.uniform(-translate_range, translate_range)]\n",
    "                \n",
    "                # test_random = [1.1, 1.1]\n",
    "                # M = np.array([[1.0 + test_random[0], 0.0, 0.0], [0.0, 1.0 + test_random[1], 0.0]])\n",
    "                scale_power = [[-1, -1], [1, 1], [-1, 1], [1, -1]]\n",
    "                rotation_direction = [-1, 1]\n",
    "                # perspective\n",
    "                rand_range = 0.001\n",
    "                \n",
    "                # perspective = [0.0007316110989513938, 0.0009501206585347142]\n",
    "                # perspective = [0.0, 0]\n",
    "\n",
    "                for k in range(4):\n",
    "                    for l in range(2):\n",
    "                        # power = scale_power[k]\n",
    "                        # sign = rotation_direction[l]\n",
    "                        # perspective = [np.random.uniform(-rand_range, rand_range), np.random.uniform(-rand_range, rand_range)]\n",
    "                        # perspective = [0.0007316110989513938, 0.0]\n",
    "                        # Combined transformation matrix for perspective, rotation, scaling, and translation\n",
    "                        # M = np.array([[sign*scaling[0]**power[0]*np.cos(rand_angle), sign*scaling[1]**power[1]*np.sin(rand_angle), translate[0]],\n",
    "                        #             [-sign*scaling[0]**power[0]*np.sin(rand_angle), sign*scaling[1]**power[1]*np.cos(rand_angle), translate[1]],\n",
    "                        #             [perspective[0], perspective[1], 1.0]])\n",
    "                        # M = np.array([[np.cos(rand_angle)*(scaling[0]**power[0]), -sign*np.sin(rand_angle), translate[0]],\n",
    "                        #             [sign*np.sin(rand_angle), np.cos(rand_angle)*(scaling[1]**power[1]), translate[1]],\n",
    "                        #             [perspective[0], perspective[1], 1.0]])\n",
    "                        \n",
    "                        # print(f'Perspective: {perspective}')\n",
    "                        # M = np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [perspective[0], perspective[1], 1.0]])\n",
    "\n",
    "                        # Calculate the transformed points\n",
    "                        width, height = image_base.shape\n",
    "                        # startpoints, endpoints = calculate_endpoints(width, height, M.flatten())\n",
    "                        \n",
    "                        # Get the perspective parameters\n",
    "                        distortion_scale = 0.1\n",
    "                        startpoints, endpoints = get_random_perspective_params(width, height, distortion_scale)\n",
    "                        distort = (k+1)*10\n",
    "                        endpoints = [[0, distort], [256, 40*l], [256, 256], [0, 256-distort]]\n",
    "                        M = calculate_perspective_matrix(startpoints, endpoints)\n",
    "                        # Apply the perspective transformation\n",
    "                        img_transformed = apply_perspective_transform(image_base, startpoints, endpoints)\n",
    "\n",
    "                        print(f'M: {M}')\n",
    "                        print(f'Startpoints: {startpoints}')\n",
    "                        print(f'Endpoints: {endpoints}\\n')\n",
    "\n",
    "                        # Apply the perspective transformation\n",
    "                        # img_transformed = apply_perspective_transform(image_base, startpoints, endpoints)\n",
    "\n",
    "                        # img_transformed, DVF = warp_image_perspective_pytorch(image_base, M)\n",
    "                        # img_transformed = img_transformed.squeeze(0).squeeze(0).numpy()\n",
    "                        # img_transformed = img_transformed[int(image.shape[0]*0.1):int(image.shape[0]*0.9), \n",
    "                        #                                 int(image.shape[1]*0.1):int(image.shape[1]*0.9)]\n",
    "\n",
    "                        # resize image to 256x256\n",
    "                        img_transformed = cv2.resize(np.array(img_transformed), (256, 256))\n",
    "                        # convert to grayscale\n",
    "                        img_transformed_BW = np.array(Image.fromarray(img_transformed).convert('L'))\n",
    "\n",
    "                        # --------------- to here\n",
    "                        # add some noise to the transformed image and save it\n",
    "                        img_transformed = img_transformed + np.random.uniform(-0.01, 0.01, img_transformed.shape)\n",
    "                        if modify: # if modify is True, then add some intensity change to the transformed image\n",
    "                            img_transformed = img_transformed + np.random.normal(1, 0.1, 1)\n",
    "\n",
    "                        # subplots: image base, transformed image, DVF\n",
    "                        # fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "                        # ax[0].imshow(image_base, cmap='gray')\n",
    "                        # ax[0].set_title('Base Image')\n",
    "                        # ax[1].imshow(img_transformed, cmap='gray')\n",
    "                        # ax[1].set_title('Transformed Image (PyTorch)')\n",
    "\n",
    "\n",
    "                        transformed_image_path = os.path.join(output_dir, f\"img_{i}_transformed_{j}_{k}_{l}.png\")\n",
    "                        cv2.imwrite(transformed_image_path, img_transformed)\n",
    "                        # ---------------\n",
    "\n",
    "                        # # TODO: save heatmaps for other version of network\n",
    "                        points2, desc2, _ = superpoint(img_transformed_BW.astype(np.float32)/255)\n",
    "                        # print(points2.shape, points2)\n",
    "                        # print(desc1.shape, desc2.shape)\n",
    "                        matches = tracker.nn_match_two_way(desc1, desc2, nn_thresh=0.7)\n",
    "\n",
    "                        # # print(desc1.shape, desc2.shape)\n",
    "                        matches1 = points1[:2, matches[0, :].astype(int)]\n",
    "                        matches1_transformed = transform_points(matches1, M)\n",
    "                        # # matches1 = matches1.T[None, :, :]\n",
    "                        matches2 = points2[:2, matches[1, :].astype(int)]\n",
    "                        # print(torch.tensor(matches1.copy()).unsqueeze(-1).view(2, -1, 1).shape, DVF.shape)\n",
    "\n",
    "                        # transform the points using the displacement field\n",
    "                        # matches1_transformed = transform_points_from_DVF(torch.tensor(matches1.copy()).unsqueeze(-1).view(2, -1, 1), \n",
    "                        #         DVF, torch.tensor(img_transformed_BW).unsqueeze(0).unsqueeze(0))\n",
    "                        # print(f'Img {i}, diff: {matches1_transformed[:, 0] - matches2[:, 0]}')\n",
    "                        # points_list.append(matches1_transformed[:, 0] - matches2[:, 0])\n",
    "\n",
    "                        # --------------- move from here ^^up\n",
    "                        # ---------------\n",
    "\n",
    "                        # create a dataframe with the matches\n",
    "                        # print(matches1.shape, matches2.shape, matches1_transformed_DVF.shape)\n",
    "                        if len(matches1_transformed.shape) == 3:\n",
    "                            matches1_transformed = matches1_transformed.squeeze(-1)\n",
    "                        df = pd.DataFrame({'x1': matches1[0, :], 'y1': matches1[1, :],\n",
    "                                        'x2': matches2[0, :], 'y2': matches2[1, :],\n",
    "                                        'x2_': matches1_transformed[0, :], 'y2_': matches1_transformed[1, :]})\n",
    "                        save_name = os.path.join(output_dir, f\"img_{i}_{j}_{k}_{l}_keypoints.csv\")\n",
    "                        df.to_csv(save_name, index=False)\n",
    "\n",
    "                        with open(csv_file, 'a', newline='') as csvfile:\n",
    "                            writer = csv.writer(csvfile)\n",
    "                            writer.writerow([original_image_path, transformed_image_path, \n",
    "                                            M[0, 0], M[0, 1], M[0, 2], M[1, 0], M[1, 1], M[1, 2], \n",
    "                                            M[2, 0], M[2, 1], M[2, 2], img_path, save_name])\n",
    "\n",
    "    print(f\"\\nGenerated {(i+1)*(num_images)} images\")\n",
    "    # print mean absolute error of the points\n",
    "    # print('MAE point location error:', np.mean(np.abs(np.array(points_list))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameters\n",
    "# output_dir = \"Dataset/synth_eye_perspetive_easy\"  # Output directory\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # plot_dir = \"Dataset/synthetic_eye_dataset_train/plot\"\n",
    "# # os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# # generate synthetic images for each source training image\n",
    "# generate_affine_transformed_images_multiple(image_list,\n",
    "#     'Dataset/synth_eye_perspetive_easy.csv', output_dir, num_images=2, modify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameters\n",
    "# image_size = (512, 512)  # Size of the images\n",
    "# output_dir = \"Dataset/synthetic_eye_dataset_train_multiple\"  # Output directory\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # plot_dir = \"Dataset/synthetic_eye_dataset_train_multiple/plot\"\n",
    "# # os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# # generate synthetic images for each source training image\n",
    "# generate_affine_transformed_images_multiple(image_list,\n",
    "#       'dataset_eye_synth_train_multiple.csv', output_dir, num_images=2, modify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12002/267543622.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['image_path'] = df_test['Directory'] + '/' + df_test['source']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 10, 256, 236\n",
      "M: tensor([[ 3.7587e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 2.7639e-06,  3.7588e-03, -6.9326e-04],\n",
      "        [-5.8486e-07,  1.5260e-05,  2.1144e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 0], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 40, 256, 206\n",
      "M: tensor([[-3.7320e-03, -3.9063e-03,  9.9998e-01],\n",
      "        [ 2.4229e-05, -3.7592e-03,  7.5415e-04],\n",
      "        [ 6.9033e-07, -1.5259e-05, -2.4137e-06]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 10], [256, 40], [256, 256], [0, 246]]\n",
      "\n",
      "crop: 0, 20, 256, 216\n",
      "M: tensor([[ 3.6033e-03,  3.9063e-03, -9.9998e-01],\n",
      "        [ 1.2439e-06,  3.6033e-03, -3.0406e-04],\n",
      "        [-1.1868e-06,  1.5260e-05,  7.7385e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 0], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 40, 256, 196\n",
      "M: tensor([[-3.5474e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 5.4737e-05, -3.6035e-03,  3.2921e-04],\n",
      "        [ 1.4057e-06, -1.5259e-05, -8.4450e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 20], [256, 40], [256, 256], [0, 236]]\n",
      "\n",
      "crop: 0, 30, 256, 196\n",
      "M: tensor([[ 3.4499e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 7.4024e-07,  3.4499e-03, -1.7610e-04],\n",
      "        [-1.7850e-06,  1.5260e-05,  4.6742e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 0], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 186\n",
      "M: tensor([[-3.3654e-03, -3.9065e-03,  9.9998e-01],\n",
      "        [ 8.3729e-05, -3.4500e-03,  1.8979e-04],\n",
      "        [ 2.1143e-06, -1.5260e-05, -4.3061e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 30], [256, 40], [256, 256], [0, 226]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[ 3.2969e-03,  3.9064e-03, -9.9998e-01],\n",
      "        [ 4.9469e-07,  3.2971e-03, -1.1334e-04],\n",
      "        [-2.3822e-06,  1.5260e-05,  5.1349e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 0], [256, 256], [0, 216]]\n",
      "\n",
      "crop: 0, 40, 256, 176\n",
      "M: tensor([[-3.1842e-03, -3.9064e-03,  9.9998e-01],\n",
      "        [ 1.1231e-04, -3.2971e-03,  1.2162e-04],\n",
      "        [ 2.8228e-06, -1.5259e-05, -5.2033e-07]])\n",
      "Startpoints: [[0, 0], [256, 0], [256, 256], [0, 256]]\n",
      "Endpoints: [[0, 40], [256, 40], [256, 256], [0, 216]]\n",
      "\n",
      "\n",
      "Generated 20 images\n"
     ]
    }
   ],
   "source": [
    "# do the same for the test images\n",
    "df_test = df[df['training'] == 1]\n",
    "df_test['image_path'] = df_test['Directory'] + '/' + df_test['source']\n",
    "image_list_test = df_test['image_path'].unique()[:5]\n",
    "\n",
    "# Define parameters\n",
    "output_dir = \"Dataset/synth_eye_perspetive_test\"  # Output directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# plot_dir = \"Dataset/synthetic_eye_dataset_test/plot\"\n",
    "# os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# generate synthetic images for each source test image\n",
    "generate_affine_transformed_images_multiple(image_list_test, \n",
    "    'Dataset/synth_eye_perspetive_test.csv', \n",
    "    output_dir, num_images=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameters\n",
    "# image_size = (512, 512)  # Size of the images\n",
    "# output_dir = \"Dataset/synthetic_eye_dataset_test_multiple\"  # Output directory\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # plot_dir = \"Dataset/synthetic_eye_dataset_test/plot\"\n",
    "# # os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# # generate synthetic images for each source test image\n",
    "# generate_affine_transformed_images_multiple(image_list_test, 'dataset_eye_synth_test_scaling.csv', output_dir, num_images=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
