{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from utils.utils0 import tensor_affine_transform, transform_to_displacement_field\n",
    "from utils.utils1 import transform_points_DVF, ModelParams\n",
    "from utils.SuperPoint import SuperPointFrontend, PointTracker\n",
    "from utils.datagen import datagen\n",
    "\n",
    "nn_thresh = 0.7\n",
    "superpoint = SuperPointFrontend('utils/superpoint_v1.pth', nms_dist=4,\n",
    "                          conf_thresh=0.015, nn_thresh=nn_thresh, cuda=True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:  dataset3_sup1_image1_heatmaps0_loss_image1\n",
      "Model code:  31101_0.0001_0_10_1\n",
      "Model params:  {'dataset': 3, 'sup': 1, 'image': 1, 'heatmaps': 0, 'loss_image_case': 1, 'loss_image': NCC(), 'loss_affine': <utils.utils1.loss_affine object at 0x7f7eef6edee0>, 'learning_rate': 0.0001, 'decay_rate': 0.96, 'start_epoch': 0, 'num_epochs': 10, 'batch_size': 1, 'model_name': 'dataset3_sup1_image1_heatmaps0_loss_image1'}\n",
      "\n",
      "Model name:  dataset3_sup1_image1_heatmaps0_loss_image1\n",
      "Model code:  31101_0.0001_0_10_1\n",
      "Dataset used:  Synthetic eye hard\n",
      "Supervised or unsupervised model:  Supervised\n",
      "Image type:  Image used\n",
      "Heatmaps used:  Heatmaps not used\n",
      "Loss function case:  1\n",
      "Loss function for image:  NCC()\n",
      "Loss function for affine:  <utils.utils1.loss_affine object at 0x7f7eef6edee0>\n",
      "Learning rate:  0.0001\n",
      "Decay rate:  0.96\n",
      "Start epoch:  0\n",
      "Number of epochs:  10\n",
      "Batch size:  1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_params = ModelParams(sup=1, dataset=3, image=1, heatmaps=0, \n",
    "                           loss_image=1, num_epochs=10, learning_rate=1e-4)\n",
    "model_params.print_explanation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_df, train_path = datagen(model_params.dataset, True, model_params.sup)\n",
    "test_dataset, test_df, test_path = datagen(model_params.dataset, False, model_params.sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>M00</th>\n",
       "      <th>M01</th>\n",
       "      <th>M02</th>\n",
       "      <th>M10</th>\n",
       "      <th>M11</th>\n",
       "      <th>M12</th>\n",
       "      <th>image_path</th>\n",
       "      <th>keypoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset/synth_eye_hard_train/img_0_original.png</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_0_transformed...</td>\n",
       "      <td>0.831559</td>\n",
       "      <td>0.127278</td>\n",
       "      <td>0.124341</td>\n",
       "      <td>-0.061596</td>\n",
       "      <td>0.845511</td>\n",
       "      <td>-0.037798</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_0_keypoints.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset/synth_eye_hard_train/img_1_original.png</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_1_transformed...</td>\n",
       "      <td>1.085117</td>\n",
       "      <td>-0.061308</td>\n",
       "      <td>0.040607</td>\n",
       "      <td>-0.176152</td>\n",
       "      <td>1.115577</td>\n",
       "      <td>0.124389</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_1_keypoints.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset/synth_eye_hard_train/img_2_original.png</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_2_transformed...</td>\n",
       "      <td>1.078080</td>\n",
       "      <td>-0.100573</td>\n",
       "      <td>-0.059993</td>\n",
       "      <td>-0.065176</td>\n",
       "      <td>1.046407</td>\n",
       "      <td>-0.097252</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_2_keypoints.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset/synth_eye_hard_train/img_3_original.png</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_3_transformed...</td>\n",
       "      <td>0.846989</td>\n",
       "      <td>0.127433</td>\n",
       "      <td>0.070412</td>\n",
       "      <td>-0.154808</td>\n",
       "      <td>0.858112</td>\n",
       "      <td>-0.075519</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_3_keypoints.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset/synth_eye_hard_train/img_4_original.png</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_4_transformed...</td>\n",
       "      <td>0.988984</td>\n",
       "      <td>0.045079</td>\n",
       "      <td>-0.198814</td>\n",
       "      <td>-0.097789</td>\n",
       "      <td>1.161455</td>\n",
       "      <td>-0.050343</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_4_keypoints.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            source  \\\n",
       "0  Dataset/synth_eye_hard_train/img_0_original.png   \n",
       "1  Dataset/synth_eye_hard_train/img_1_original.png   \n",
       "2  Dataset/synth_eye_hard_train/img_2_original.png   \n",
       "3  Dataset/synth_eye_hard_train/img_3_original.png   \n",
       "4  Dataset/synth_eye_hard_train/img_4_original.png   \n",
       "\n",
       "                                              target       M00       M01  \\\n",
       "0  Dataset/synth_eye_hard_train/img_0_transformed...  0.831559  0.127278   \n",
       "1  Dataset/synth_eye_hard_train/img_1_transformed...  1.085117 -0.061308   \n",
       "2  Dataset/synth_eye_hard_train/img_2_transformed...  1.078080 -0.100573   \n",
       "3  Dataset/synth_eye_hard_train/img_3_transformed...  0.846989  0.127433   \n",
       "4  Dataset/synth_eye_hard_train/img_4_transformed...  0.988984  0.045079   \n",
       "\n",
       "        M02       M10       M11       M12  \\\n",
       "0  0.124341 -0.061596  0.845511 -0.037798   \n",
       "1  0.040607 -0.176152  1.115577  0.124389   \n",
       "2 -0.059993 -0.065176  1.046407 -0.097252   \n",
       "3  0.070412 -0.154808  0.858112 -0.075519   \n",
       "4 -0.198814 -0.097789  1.161455 -0.050343   \n",
       "\n",
       "                                          image_path  \\\n",
       "0  Dataset/Dataset-processed/15-12-2559/2011248/L...   \n",
       "1  Dataset/Dataset-processed/15-12-2559/2011248/L...   \n",
       "2  Dataset/Dataset-processed/15-12-2559/2011248/R...   \n",
       "3  Dataset/Dataset-processed/15-12-2559/2011248/R...   \n",
       "4  Dataset/Dataset-processed/15-12-2559/2011248/R...   \n",
       "\n",
       "                                          keypoints  \n",
       "0  Dataset/synth_eye_hard_train/img_0_keypoints.csv  \n",
       "1  Dataset/synth_eye_hard_train/img_1_keypoints.csv  \n",
       "2  Dataset/synth_eye_hard_train/img_2_keypoints.csv  \n",
       "3  Dataset/synth_eye_hard_train/img_3_keypoints.csv  \n",
       "4  Dataset/synth_eye_hard_train/img_4_keypoints.csv  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>M00</th>\n",
       "      <th>M01</th>\n",
       "      <th>M02</th>\n",
       "      <th>M10</th>\n",
       "      <th>M11</th>\n",
       "      <th>M12</th>\n",
       "      <th>image_path</th>\n",
       "      <th>keypoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset/synth_eye_hard_train/img_0_original.png</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_0_transformed...</td>\n",
       "      <td>0.831559</td>\n",
       "      <td>0.127278</td>\n",
       "      <td>0.124341</td>\n",
       "      <td>-0.061596</td>\n",
       "      <td>0.845511</td>\n",
       "      <td>-0.037798</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_0_keypoints.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset/synth_eye_hard_train/img_1_original.png</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_1_transformed...</td>\n",
       "      <td>1.085117</td>\n",
       "      <td>-0.061308</td>\n",
       "      <td>0.040607</td>\n",
       "      <td>-0.176152</td>\n",
       "      <td>1.115577</td>\n",
       "      <td>0.124389</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_1_keypoints.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset/synth_eye_hard_train/img_2_original.png</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_2_transformed...</td>\n",
       "      <td>1.078080</td>\n",
       "      <td>-0.100573</td>\n",
       "      <td>-0.059993</td>\n",
       "      <td>-0.065176</td>\n",
       "      <td>1.046407</td>\n",
       "      <td>-0.097252</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_2_keypoints.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset/synth_eye_hard_train/img_3_original.png</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_3_transformed...</td>\n",
       "      <td>0.846989</td>\n",
       "      <td>0.127433</td>\n",
       "      <td>0.070412</td>\n",
       "      <td>-0.154808</td>\n",
       "      <td>0.858112</td>\n",
       "      <td>-0.075519</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_3_keypoints.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset/synth_eye_hard_train/img_4_original.png</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_4_transformed...</td>\n",
       "      <td>0.988984</td>\n",
       "      <td>0.045079</td>\n",
       "      <td>-0.198814</td>\n",
       "      <td>-0.097789</td>\n",
       "      <td>1.161455</td>\n",
       "      <td>-0.050343</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "      <td>Dataset/synth_eye_hard_train/img_4_keypoints.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            source  \\\n",
       "0  Dataset/synth_eye_hard_train/img_0_original.png   \n",
       "1  Dataset/synth_eye_hard_train/img_1_original.png   \n",
       "2  Dataset/synth_eye_hard_train/img_2_original.png   \n",
       "3  Dataset/synth_eye_hard_train/img_3_original.png   \n",
       "4  Dataset/synth_eye_hard_train/img_4_original.png   \n",
       "\n",
       "                                              target       M00       M01  \\\n",
       "0  Dataset/synth_eye_hard_train/img_0_transformed...  0.831559  0.127278   \n",
       "1  Dataset/synth_eye_hard_train/img_1_transformed...  1.085117 -0.061308   \n",
       "2  Dataset/synth_eye_hard_train/img_2_transformed...  1.078080 -0.100573   \n",
       "3  Dataset/synth_eye_hard_train/img_3_transformed...  0.846989  0.127433   \n",
       "4  Dataset/synth_eye_hard_train/img_4_transformed...  0.988984  0.045079   \n",
       "\n",
       "        M02       M10       M11       M12  \\\n",
       "0  0.124341 -0.061596  0.845511 -0.037798   \n",
       "1  0.040607 -0.176152  1.115577  0.124389   \n",
       "2 -0.059993 -0.065176  1.046407 -0.097252   \n",
       "3  0.070412 -0.154808  0.858112 -0.075519   \n",
       "4 -0.198814 -0.097789  1.161455 -0.050343   \n",
       "\n",
       "                                          image_path  \\\n",
       "0  Dataset/Dataset-processed/15-12-2559/2011248/L...   \n",
       "1  Dataset/Dataset-processed/15-12-2559/2011248/L...   \n",
       "2  Dataset/Dataset-processed/15-12-2559/2011248/R...   \n",
       "3  Dataset/Dataset-processed/15-12-2559/2011248/R...   \n",
       "4  Dataset/Dataset-processed/15-12-2559/2011248/R...   \n",
       "\n",
       "                                          keypoints  \n",
       "0  Dataset/synth_eye_hard_train/img_0_keypoints.csv  \n",
       "1  Dataset/synth_eye_hard_train/img_1_keypoints.csv  \n",
       "2  Dataset/synth_eye_hard_train/img_2_keypoints.csv  \n",
       "3  Dataset/synth_eye_hard_train/img_3_keypoints.csv  \n",
       "4  Dataset/synth_eye_hard_train/img_4_keypoints.csv  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add one column to the dataframe to store the path to keypoints file\n",
    "train_df['keypoints'] = train_df['source'].apply(lambda x: x.replace('_original.png', '_keypoints.csv'))\n",
    "test_df['keypoints'] = test_df['source'].apply(lambda x: x.replace('_original.png', '_keypoints.csv'))\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "train_df.to_csv('Dataset/synth_eye_hard_train.csv', index=False)\n",
    "test_df.to_csv('Dataset/synth_eye_hard_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_183540/867371186.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  affine_params_true = torch.tensor(affine_params_true)\n",
      "/home/pkhamchuai/miniconda3/envs/spppt/lib/python3.8/site-packages/torch/nn/functional.py:4358: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/pkhamchuai/miniconda3/envs/spppt/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Train: 100%|██████████| 200/200 [00:32<00:00,  6.22it/s]\n"
     ]
    }
   ],
   "source": [
    "train_bar = tqdm(train_dataset, total=len(train_dataset), desc='Train')\n",
    "for i, data in enumerate(train_bar):\n",
    "\n",
    "    # Get images and affine parameters\n",
    "    if model_params.sup:\n",
    "        source_image, target_image, affine_params_true = data\n",
    "        affine_params_true = torch.tensor(affine_params_true)\n",
    "    else:\n",
    "        source_image, target_image = data\n",
    "        affine_params_true = None\n",
    "    source_image = source_image.to(device)\n",
    "    target_image = target_image.to(device)\n",
    "\n",
    "    points1, desc1, heatmap1 = superpoint(source_image[0, 0, :, :].cpu().numpy())\n",
    "    points2, desc2, heatmap2 = superpoint(target_image[0, 0, :, :].cpu().numpy())\n",
    "\n",
    "    tracker = PointTracker(5, nn_thresh=0.7)\n",
    "    try:\n",
    "        matches = tracker.nn_match_two_way(desc1, desc2, nn_thresh=nn_thresh)\n",
    "    except:\n",
    "        print('No matches found')\n",
    "        # TODO: find a better way to do this\n",
    "        pass\n",
    "\n",
    "    matches1 = np.array(points1[:2, matches[0, :].astype(int)])\n",
    "    matches2 = np.array(points2[:2, matches[1, :].astype(int)])\n",
    "    matches1_2 = transform_points_DVF(torch.tensor(matches1), \n",
    "                        affine_params_true, target_image)\n",
    "    \n",
    "    # fig, ax = plt.subplots(1, 2)\n",
    "    # ax[0].imshow(source_image[0, 0, :, :].cpu().detach().numpy())\n",
    "    # ax[0].plot(matches1[0, :], matches1[1, :], 'r.')\n",
    "    # ax[1].imshow(target_image[0, 0, :, :].cpu().detach().numpy())\n",
    "    # ax[1].plot(matches2[0, :], matches2[1, :], 'g.')\n",
    "    # ax[1].plot(matches1_2[0, :], matches1_2[1, :], 'r.')\n",
    "    # plt.show()\n",
    "\n",
    "    # create a dataframe with the matches\n",
    "    df = pd.DataFrame({'x1': matches1[0, :], 'y1': matches1[1, :],\n",
    "                       'x2': matches2[0, :], 'y2': matches2[1, :],\n",
    "                       'x2_': matches1_2[0, :], 'y2_': matches1_2[1, :]})\n",
    "    save_name = train_df['keypoints'].iloc[i]\n",
    "    df.to_csv(save_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   0%|          | 0/100 [00:00<?, ?it/s]/tmp/ipykernel_183540/806415840.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  affine_params_true = torch.tensor(affine_params_true)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 100/100 [00:16<00:00,  5.97it/s]\n"
     ]
    }
   ],
   "source": [
    "test_bar = tqdm(test_dataset, total=len(test_dataset), desc='Test')\n",
    "for i, data in enumerate(test_bar):\n",
    "\n",
    "    # Get images and affine parameters\n",
    "    if model_params.sup:\n",
    "        source_image, target_image, affine_params_true = data\n",
    "        affine_params_true = torch.tensor(affine_params_true)\n",
    "    else:\n",
    "        source_image, target_image = data\n",
    "        affine_params_true = None\n",
    "    source_image = source_image.to(device)\n",
    "    target_image = target_image.to(device)\n",
    "\n",
    "    points1, desc1, heatmap1 = superpoint(source_image[0, 0, :, :].cpu().numpy())\n",
    "    points2, desc2, heatmap2 = superpoint(target_image[0, 0, :, :].cpu().numpy())\n",
    "\n",
    "    tracker = PointTracker(5, nn_thresh=0.7)\n",
    "    try:\n",
    "        matches = tracker.nn_match_two_way(desc1, desc2, nn_thresh=nn_thresh)\n",
    "    except:\n",
    "        print('No matches found')\n",
    "        # TODO: find a better way to do this\n",
    "        pass\n",
    "\n",
    "    matches1 = np.array(points1[:2, matches[0, :].astype(int)])\n",
    "    matches2 = np.array(points2[:2, matches[1, :].astype(int)])\n",
    "    matches1_2 = transform_points_DVF(torch.tensor(matches1), \n",
    "                        affine_params_true, target_image)\n",
    "    \n",
    "    # fig, ax = plt.subplots(1, 2)\n",
    "    # ax[0].imshow(source_image[0, 0, :, :].cpu().detach().numpy())\n",
    "    # ax[0].plot(matches1[0, :], matches1[1, :], 'r.')\n",
    "    # ax[1].imshow(target_image[0, 0, :, :].cpu().detach().numpy())\n",
    "    # ax[1].plot(matches2[0, :], matches2[1, :], 'g.')\n",
    "    # ax[1].plot(matches1_2[0, :], matches1_2[1, :], 'r.')\n",
    "    # plt.show()\n",
    "\n",
    "    # create a dataframe with the matches\n",
    "    df = pd.DataFrame({'x1': matches1[0, :], 'y1': matches1[1, :],\n",
    "                       'x2': matches2[0, :], 'y2': matches2[1, :],\n",
    "                       'x2_': matches1_2[0, :], 'y2_': matches1_2[1, :]})\n",
    "    save_name = test_df['keypoints'].iloc[i]\n",
    "    df.to_csv(save_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# verify that the saved keypoints are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spppt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
