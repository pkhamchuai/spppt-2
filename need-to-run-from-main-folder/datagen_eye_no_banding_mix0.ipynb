{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "(5040, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pakpoom/codes/spppt-2/utils/SuperPoint.py:91: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.net.load_state_dict(torch.load(weights_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>Source ROI</th>\n",
       "      <th>target</th>\n",
       "      <th>Target ROI</th>\n",
       "      <th>training</th>\n",
       "      <th>Warped target images</th>\n",
       "      <th>Warped target ROI</th>\n",
       "      <th>Execution time</th>\n",
       "      <th>Directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011248_20161215__L_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_b1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011248_20161215__L_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_b3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011248_20161215__L_b1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_b3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       source  Source ROI                      target  \\\n",
       "0  2011248_20161215__L_b2.jpg         NaN  2011248_20161215__L_b1.jpg   \n",
       "1  2011248_20161215__L_b2.jpg         NaN  2011248_20161215__L_b3.jpg   \n",
       "2  2011248_20161215__L_b1.jpg         NaN  2011248_20161215__L_b3.jpg   \n",
       "3  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c1.jpg   \n",
       "4  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c3.jpg   \n",
       "\n",
       "   Target ROI  training  Warped target images  Warped target ROI  \\\n",
       "0         NaN         1                   NaN                NaN   \n",
       "1         NaN         1                   NaN                NaN   \n",
       "2         NaN         1                   NaN                NaN   \n",
       "3         NaN         0                   NaN                NaN   \n",
       "4         NaN         0                   NaN                NaN   \n",
       "\n",
       "   Execution time                                        Directory  \n",
       "0             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lb  \n",
       "1             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lb  \n",
       "2             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lb  \n",
       "3             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lc  \n",
       "4             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lc  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the file 'dataset_reg_pair_filled.csv' and generate synthetic data\n",
    "# first read the file, then make a list of the source training images\n",
    "# then for each image, generate 10 synthetic images with random affine transformation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils.utils0 import tensor_affine_transform, transform_to_displacement_field\n",
    "from utils.utils1 import transform_points_DVF\n",
    "from utils.SuperPoint import SuperPointFrontend, PointTracker\n",
    "superpoint = SuperPointFrontend('utils/superpoint_v1.pth', nms_dist=4,\n",
    "                          conf_thresh=0.015, nn_thresh=0.7, cuda=True)\n",
    "\n",
    "# read the file\n",
    "df = pd.read_csv('Dataset/dataset_reg_pair_filled.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_484980/1623562252.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['image_path'] = df_train['Directory'] + '/' + df_train['source']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>Source ROI</th>\n",
       "      <th>target</th>\n",
       "      <th>Target ROI</th>\n",
       "      <th>training</th>\n",
       "      <th>Warped target images</th>\n",
       "      <th>Warped target ROI</th>\n",
       "      <th>Execution time</th>\n",
       "      <th>Directory</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011248_20161215__L_c1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011248_20161215__R_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__R_b3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Rb</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011248_20161215__R_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__R_b1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Rb</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       source  Source ROI                      target  \\\n",
       "3  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c1.jpg   \n",
       "4  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c3.jpg   \n",
       "5  2011248_20161215__L_c1.jpg         NaN  2011248_20161215__L_c3.jpg   \n",
       "6  2011248_20161215__R_b2.jpg         NaN  2011248_20161215__R_b3.jpg   \n",
       "7  2011248_20161215__R_b2.jpg         NaN  2011248_20161215__R_b1.jpg   \n",
       "\n",
       "   Target ROI  training  Warped target images  Warped target ROI  \\\n",
       "3         NaN         0                   NaN                NaN   \n",
       "4         NaN         0                   NaN                NaN   \n",
       "5         NaN         0                   NaN                NaN   \n",
       "6         NaN         0                   NaN                NaN   \n",
       "7         NaN         0                   NaN                NaN   \n",
       "\n",
       "   Execution time                                        Directory  \\\n",
       "3             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lc   \n",
       "4             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lc   \n",
       "5             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Lc   \n",
       "6             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Rb   \n",
       "7             NaN  Dataset/Dataset-processed/15-12-2559/2011248/Rb   \n",
       "\n",
       "                                          image_path  \n",
       "3  Dataset/Dataset-processed/15-12-2559/2011248/L...  \n",
       "4  Dataset/Dataset-processed/15-12-2559/2011248/L...  \n",
       "5  Dataset/Dataset-processed/15-12-2559/2011248/L...  \n",
       "6  Dataset/Dataset-processed/15-12-2559/2011248/R...  \n",
       "7  Dataset/Dataset-processed/15-12-2559/2011248/R...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a list of the unique source training images that has 'training' = 0\n",
    "# each image path consists of image directory, image name\n",
    "\n",
    "df_train = df[df['training'] == 0]\n",
    "\n",
    "# create a new df consists of image directory and image name concatenated\n",
    "df_train['image_path'] = df_train['Directory'] + '/' + df_train['source']\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4132, 10)\n",
      "500\n",
      "Dataset/Dataset-processed/15-12-2559/2011248/Lc/2011248_20161215__L_c2.jpg\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "# make a list of the unique values in the column 'image_path'\n",
    "image_list = df_train['image_path'].unique()[:500]\n",
    "print(len(image_list))\n",
    "print(image_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_translation = 0.1  # Minimum translation in pixels\n",
    "max_translation = 0.2  # Maximum translation in pixels\n",
    "max_rotation = 20  # Maximum rotation in degrees\n",
    "max_shear = 10  # Maximum shear in degrees\n",
    "min_scale = 0.85  # Minimum scale factor\n",
    "max_scale = 1.15  # Maximum scale factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train translate: (1000, 10)\n",
      "Train scaling: (4000, 10)\n",
      "Train rotate: (3000, 10)\n",
      "Train shear: (8000, 10)\n",
      "Train: (16000, 10)\n"
     ]
    }
   ],
   "source": [
    "# read dataset csv files\n",
    "df_train_translate = pd.read_csv('Dataset/synth_eye_translate_train_2.csv')\n",
    "df_train_scaling = pd.read_csv('Dataset/synth_eye_scaling_train_2.csv')\n",
    "df_train_rotate = pd.read_csv('Dataset/synth_eye_rotate_train_2.csv')\n",
    "df_train_shear = pd.read_csv('Dataset/synth_eye_shear_train_2.csv')\n",
    "\n",
    "print(f'Train translate: {df_train_translate.shape}')\n",
    "print(f'Train scaling: {df_train_scaling.shape}')\n",
    "print(f'Train rotate: {df_train_rotate.shape}')\n",
    "print(f'Train shear: {df_train_shear.shape}')\n",
    "\n",
    "\n",
    "df_train_csv = pd.concat([df_train_translate, df_train_scaling])\n",
    "df_train_csv = pd.concat([df_train_csv, df_train_rotate])\n",
    "df_train_csv = pd.concat([df_train_csv, df_train_shear])\n",
    "print(f'Train: {df_train_csv.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test translate: (200, 10)\n",
      "Test scaling: (100, 10)\n",
      "Test rotate: (250, 10)\n",
      "Test shear: (250, 10)\n",
      "Test: (800, 10)\n"
     ]
    }
   ],
   "source": [
    "# df_test_translate = pd.read_csv('Dataset/synth_eye_translate_test.csv')\n",
    "# df_test_scaling = pd.read_csv('Dataset/synth_eye_scaling_test.csv')\n",
    "# df_test_rotate = pd.read_csv('Dataset/synth_eye_rotate_test.csv')\n",
    "# df_test_shear = pd.read_csv('Dataset/synth_eye_shear_test.csv')\n",
    "\n",
    "# print(f'Test translate: {df_test_translate.shape}')\n",
    "# print(f'Test scaling: {df_test_scaling.shape}')\n",
    "# print(f'Test rotate: {df_test_rotate.shape}')\n",
    "# print(f'Test shear: {df_test_shear.shape}')\n",
    "\n",
    "# df_test_csv = pd.concat([df_test_translate, df_test_scaling])\n",
    "# df_test_csv = pd.concat([df_test_csv, df_test_rotate])\n",
    "# df_test_csv = pd.concat([df_test_csv, df_test_shear])\n",
    "# print(f'Test: {df_test_csv.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_csv.to_csv('Dataset/synth_eye_mix0_train_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_csv.to_csv('Dataset/synth_eye_mix0_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply all transformations to the eye images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_affine_transformed_images_multiple(img_list, csv_file, output_dir, df_other_set, num_images=5, modify=False):\n",
    "    # delete all files and subdirectories in the output directory\n",
    "    shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # create a list to store different point locations\n",
    "    points_list = []\n",
    "\n",
    "    # Initialize the CSV file with a header\n",
    "    with open(csv_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"source\", \"target\", \"M00\", \"M01\", \"M02\", \"M10\", \"M11\", \"M12\", \"image_path\", \"keypoints\"])\n",
    "\n",
    "    # Loop over the images, read the image, \n",
    "    # apply affine transformation and save it\n",
    "    for i, img_path in enumerate(img_list):\n",
    "        # if i > len(img_list)/2:\n",
    "        #     break\n",
    "        # Read the image as grayscale using cv2\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Save original image\n",
    "        original_image_path = os.path.join(output_dir, f\"img_{i}_original.png\")\n",
    "\n",
    "        # take 90% of the image\n",
    "        image_base = image[int(image.shape[0]*0.1):int(image.shape[0]*0.9), \n",
    "                        int(image.shape[1]*0.1):int(image.shape[1]*0.9)]\n",
    "        # resize image to 256x256\n",
    "        image_base = cv2.resize(image_base, (256, 256))\n",
    "\n",
    "        cv2.imwrite(original_image_path, image_base + np.random.uniform(-0.01, 0.01, image_base.shape))\n",
    "\n",
    "        # Convert the transformed image to a numpy array\n",
    "        # img_transformed = np.array(img_transformed)\n",
    "        image_base = np.array(Image.fromarray(image_base).convert('L'))\n",
    "\n",
    "        tracker = PointTracker(5, nn_thresh=0.7)\n",
    "        points1, desc1, _ = superpoint(image_base.astype(np.float32)/255)\n",
    "\n",
    "        for j in range(num_images):\n",
    "            # random (2x3) affine transformation matrix\n",
    "            #M = np.array([[1.0, 0.0, np.random()], [0.0, 1.0, 0.0]])\n",
    "            if j == num_images-1:\n",
    "                # pass\n",
    "                img_transformed = image_base.copy()\n",
    "                M = np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]])\n",
    "                points2 = points1.copy()\n",
    "                desc2 = desc1.copy()\n",
    "                \n",
    "                img_transformed = cv2.resize(img_transformed, (256, 256))\n",
    "                # convert to grayscale\n",
    "                img_transformed_BW = np.array(Image.fromarray(img_transformed).convert('L'))\n",
    "\n",
    "                # # TODO: save heatmaps for other version of network\n",
    "                points2, desc2, _ = superpoint(img_transformed_BW.astype(np.float32)/255)\n",
    "                matches = tracker.nn_match_two_way(desc1, desc2, nn_thresh=0.7)\n",
    "\n",
    "                # # print(desc1.shape, desc2.shape)\n",
    "                matches1 = points1[:2, matches[0, :].astype(int)]\n",
    "                # # matches1 = matches1.T[None, :, :]\n",
    "                matches2 = points2[:2, matches[1, :].astype(int)]\n",
    "                \n",
    "                # transform the points using the displacement field\n",
    "                # print(torch.tensor(M)[None, :, :].shape, torch.tensor(image)[None, None, :, :].shape)\n",
    "                # print(torch.tensor(M).shape, torch.tensor(image).shape, torch.tensor(matches1.copy()).unsqueeze(-1).view(2, -1, 1).shape)\n",
    "                matches1_transformed_DVF = transform_points_DVF(torch.tensor(matches1.copy()).unsqueeze(-1).view(2, -1, 1), \n",
    "                    torch.tensor(M).view(1, 2, 3), torch.tensor(image_base).unsqueeze(0).unsqueeze(0))\n",
    "                # print(f'Img {i}, diff: {matches1_transformed_DVF[:, 0] - matches2[:, 0]}')\n",
    "                # points_list.append(matches1_transformed_DVF[:, 0] - matches2[:, 0])\n",
    "\n",
    "                # add some noise to the transformed image and save it\n",
    "                img_transformed = img_transformed + np.random.uniform(-0.01, 0.01, img_transformed.shape)\n",
    "                if modify: # if modify is True, then add some intensity change to the transformed image\n",
    "                    img_transformed = img_transformed + np.random.normal(1, 0.1, 1)\n",
    "\n",
    "\n",
    "                transformed_image_path = os.path.join(output_dir, f\"img_{i}_transformed_{j}.png\")\n",
    "                cv2.imwrite(transformed_image_path, img_transformed)\n",
    "\n",
    "                # create a dataframe with the matches\n",
    "                # print(matches1.shape, matches2.shape, matches1_transformed_DVF.shape)\n",
    "                if len(matches1_transformed_DVF.shape) == 3:\n",
    "                    matches1_transformed_DVF = matches1_transformed_DVF.squeeze(-1)\n",
    "                df = pd.DataFrame({'x1': matches1[0, :], 'y1': matches1[1, :],\n",
    "                                'x2': matches2[0, :], 'y2': matches2[1, :],\n",
    "                                'x2_': matches1_transformed_DVF[0, :], 'y2_': matches1_transformed_DVF[1, :]})\n",
    "                save_name = os.path.join(output_dir, f\"img_{i}_{j}_keypoints.csv\")\n",
    "                df.to_csv(save_name, index=False)\n",
    "\n",
    "                with open(csv_file, 'a', newline='') as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerow([original_image_path, transformed_image_path, \n",
    "                                    M[0, 0], M[0, 1], M[0, 2], M[1, 0], M[1, 1], M[1, 2], img_path, save_name])\n",
    "            \n",
    "            else:\n",
    "                rand_angle = np.random.uniform(0, max_rotation)/180*np.pi\n",
    "                rand_range = 1.2\n",
    "                scaling = [np.random.uniform(1, rand_range), np.random.uniform(1, rand_range)]\n",
    "                # rand_angle = 10/180*np.pi\n",
    "                translate_range = 0.1\n",
    "                translate = [np.random.uniform(-translate_range, translate_range), np.random.uniform(-translate_range, translate_range)]\n",
    "                \n",
    "                # test_random = [1.1, 1.1]\n",
    "                # M = np.array([[1.0 + test_random[0], 0.0, 0.0], [0.0, 1.0 + test_random[1], 0.0]])\n",
    "                scale_power = [[-1, -1], [1, 1], [-1, 1], [1, -1]]\n",
    "                rotation_direction = [-1, 1]\n",
    "                for k in range(4):\n",
    "                    for l in range(2):\n",
    "                        power = scale_power[k]\n",
    "                        sign = rotation_direction[l]\n",
    "                        \n",
    "                        \n",
    "                        # print(f'Img {i}, {power}, {sign}')\n",
    "                        M = np.array([[np.cos(rand_angle)*(scaling[0]**power[0]), \n",
    "                                    -sign*np.sin(rand_angle), translate[0]],\n",
    "                                    [sign*np.sin(rand_angle), np.cos(rand_angle)*(scaling[1]**power[1]), translate[1]]])\n",
    "                        # M = np.array([[0.8, 0.0, 0.0], \n",
    "                        #               [0.0, 0.8, 0.0]])\n",
    "\n",
    "                        img_transformed = tensor_affine_transform(torch.tensor(image).unsqueeze(0).unsqueeze(0).float(), torch.tensor(M).unsqueeze(0).float())\n",
    "                        img_transformed = img_transformed.squeeze(0).squeeze(0).numpy()\n",
    "                        img_transformed = img_transformed[int(image.shape[0]*0.1):int(image.shape[0]*0.9), \n",
    "                                                        int(image.shape[1]*0.1):int(image.shape[1]*0.9)]\n",
    "\n",
    "                        # resize image to 256x256\n",
    "                        img_transformed = cv2.resize(img_transformed, (256, 256))\n",
    "                        # convert to grayscale\n",
    "                        img_transformed_BW = np.array(Image.fromarray(img_transformed).convert('L'))\n",
    "\n",
    "                        # # TODO: save heatmaps for other version of network\n",
    "                        points2, desc2, _ = superpoint(img_transformed_BW.astype(np.float32)/255)\n",
    "                        matches = tracker.nn_match_two_way(desc1, desc2, nn_thresh=0.7)\n",
    "\n",
    "                        # # print(desc1.shape, desc2.shape)\n",
    "                        matches1 = points1[:2, matches[0, :].astype(int)]\n",
    "                        # # matches1 = matches1.T[None, :, :]\n",
    "                        matches2 = points2[:2, matches[1, :].astype(int)]\n",
    "                        \n",
    "                        # transform the points using the displacement field\n",
    "                        # print(torch.tensor(M)[None, :, :].shape, torch.tensor(image)[None, None, :, :].shape)\n",
    "                        # print(torch.tensor(M).shape, torch.tensor(image).shape, torch.tensor(matches1.copy()).unsqueeze(-1).view(2, -1, 1).shape)\n",
    "                        matches1_transformed_DVF = transform_points_DVF(torch.tensor(matches1.copy()).unsqueeze(-1).view(2, -1, 1), \n",
    "                            torch.tensor(M).view(1, 2, 3), torch.tensor(image_base).unsqueeze(0).unsqueeze(0))\n",
    "                        # print(f'Img {i}, diff: {matches1_transformed_DVF[:, 0] - matches2[:, 0]}')\n",
    "                        # points_list.append(matches1_transformed_DVF[:, 0] - matches2[:, 0])\n",
    "\n",
    "                        # add some noise to the transformed image and save it\n",
    "                        img_transformed = img_transformed + np.random.uniform(-0.01, 0.01, img_transformed.shape)\n",
    "                        if modify: # if modify is True, then add some intensity change to the transformed image\n",
    "                            img_transformed = img_transformed + np.random.normal(1, 0.1, 1)\n",
    "\n",
    "\n",
    "                        transformed_image_path = os.path.join(output_dir, f\"img_{i}_transformed_{j}_{k}_{l}.png\")\n",
    "                        cv2.imwrite(transformed_image_path, img_transformed)\n",
    "\n",
    "                        # create a dataframe with the matches\n",
    "                        # print(matches1.shape, matches2.shape, matches1_transformed_DVF.shape)\n",
    "                        if len(matches1_transformed_DVF.shape) == 3:\n",
    "                            matches1_transformed_DVF = matches1_transformed_DVF.squeeze(-1)\n",
    "                        df = pd.DataFrame({'x1': matches1[0, :], 'y1': matches1[1, :],\n",
    "                                        'x2': matches2[0, :], 'y2': matches2[1, :],\n",
    "                                        'x2_': matches1_transformed_DVF[0, :], 'y2_': matches1_transformed_DVF[1, :]})\n",
    "                        save_name = os.path.join(output_dir, f\"img_{i}_{j}_{k}_{l}_keypoints.csv\")\n",
    "                        df.to_csv(save_name, index=False)\n",
    "\n",
    "                        with open(csv_file, 'a', newline='') as csvfile:\n",
    "                            writer = csv.writer(csvfile)\n",
    "                            writer.writerow([original_image_path, transformed_image_path, \n",
    "                                            M[0, 0], M[0, 1], M[0, 2], M[1, 0], M[1, 1], M[1, 2], img_path, save_name])\n",
    "                            \n",
    "    # write rows of df_other_set to csv_file\n",
    "    with open(csv_file, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for j in range(df_other_set.shape[0]):\n",
    "            writer.writerow(df_other_set.iloc[j].values)\n",
    "\n",
    "    print(f\"\\nGenerated {(i+1)*(num_images)} images\")\n",
    "    # print mean absolute error of the points\n",
    "    # print('MAE point location error:', np.mean(np.abs(np.array(points_list))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated 1500 images\n"
     ]
    }
   ],
   "source": [
    "# # Define parameters\n",
    "# output_dir = \"Dataset/synth_eye_mix_train\"  # Output directory\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # plot_dir = \"Dataset/synthetic_eye_dataset_train/plot\"\n",
    "# # os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# # generate synthetic images for each source training image\n",
    "# generate_affine_transformed_images_multiple(image_list,\n",
    "#     'Dataset/synth_eye_mix_train.csv', output_dir, df_train_csv, num_images=3, modify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameters\n",
    "# image_size = (512, 512)  # Size of the images\n",
    "# output_dir = \"Dataset/synthetic_eye_dataset_train_multiple\"  # Output directory\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # plot_dir = \"Dataset/synthetic_eye_dataset_train_multiple/plot\"\n",
    "# # os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# # generate synthetic images for each source training image\n",
    "# generate_affine_transformed_images_multiple(image_list,'dataset_eye_synth_train_multiple.csv', output_dir, num_images=2, modify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12187/686737539.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['image_path'] = df_test['Directory'] + '/' + df_test['source']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated 100 images\n"
     ]
    }
   ],
   "source": [
    "# # do the same for the test images\n",
    "# df_test = df[df['training'] == 1]\n",
    "# df_test['image_path'] = df_test['Directory'] + '/' + df_test['source']\n",
    "# image_list_test = df_test['image_path'].unique()[:50]\n",
    "\n",
    "# # Define parameters\n",
    "# output_dir = \"Dataset/synth_eye_mix_test\"  # Output directory\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # plot_dir = \"Dataset/synthetic_eye_dataset_test/plot\"\n",
    "# # os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# # generate synthetic images for each source test image\n",
    "# generate_affine_transformed_images_multiple(image_list_test, 'Dataset/synth_eye_mix_test.csv', \n",
    "#                                             output_dir, df_test_csv, num_images=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define parameters\n",
    "# image_size = (512, 512)  # Size of the images\n",
    "# output_dir = \"Dataset/synthetic_eye_dataset_test_multiple\"  # Output directory\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # plot_dir = \"Dataset/synthetic_eye_dataset_test/plot\"\n",
    "# # os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# # generate synthetic images for each source test image\n",
    "# generate_affine_transformed_images_multiple(image_list_test, 'dataset_eye_synth_test_scaling.csv', output_dir, num_images=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
