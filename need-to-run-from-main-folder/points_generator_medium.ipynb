{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from utils.utils0 import tensor_affine_transform, transform_to_displacement_field\n",
    "from utils.utils1 import transform_points_DVF, ModelParams\n",
    "from utils.SuperPoint import SuperPointFrontend, PointTracker\n",
    "from utils.datagen import datagen\n",
    "\n",
    "nn_thresh = 0.7\n",
    "superpoint = SuperPointFrontend('utils/superpoint_v1.pth', nms_dist=4,\n",
    "                          conf_thresh=0.015, nn_thresh=nn_thresh, cuda=True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:  dataset2_sup1_image1_heatmaps0_loss_image1\n",
      "Model code:  21101_0.0001_0_10_1\n",
      "Model params:  {'dataset': 2, 'sup': 1, 'image': 1, 'heatmaps': 0, 'loss_image_case': 1, 'loss_image': NCC(), 'loss_affine': <utils.utils1.loss_affine object at 0x7ff2a81e6820>, 'learning_rate': 0.0001, 'decay_rate': 0.96, 'start_epoch': 0, 'num_epochs': 10, 'batch_size': 1, 'model_name': 'dataset2_sup1_image1_heatmaps0_loss_image1'}\n",
      "\n",
      "Model name:  dataset2_sup1_image1_heatmaps0_loss_image1\n",
      "Model code:  21101_0.0001_0_10_1\n",
      "Dataset used:  Synthetic eye medium\n",
      "Supervised or unsupervised model:  Supervised\n",
      "Image type:  Image used\n",
      "Heatmaps used:  Heatmaps not used\n",
      "Loss function case:  1\n",
      "Loss function for image:  NCC()\n",
      "Loss function for affine:  <utils.utils1.loss_affine object at 0x7ff2a81e6820>\n",
      "Learning rate:  0.0001\n",
      "Decay rate:  0.96\n",
      "Start epoch:  0\n",
      "Number of epochs:  10\n",
      "Batch size:  1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_params = ModelParams(sup=1, dataset=2, image=1, heatmaps=0, \n",
    "                           loss_image=1, num_epochs=10, learning_rate=1e-4)\n",
    "model_params.print_explanation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_df, train_path = datagen(model_params.dataset, True, model_params.sup)\n",
    "test_dataset, test_df, test_path = datagen(model_params.dataset, False, model_params.sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>M00</th>\n",
       "      <th>M01</th>\n",
       "      <th>M02</th>\n",
       "      <th>M10</th>\n",
       "      <th>M11</th>\n",
       "      <th>M12</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset/synth_eye_medium_train/img_0_original.png</td>\n",
       "      <td>Dataset/synth_eye_medium_train/img_0_transform...</td>\n",
       "      <td>1.160598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.119816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.121060</td>\n",
       "      <td>-0.031026</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset/synth_eye_medium_train/img_1_original.png</td>\n",
       "      <td>Dataset/synth_eye_medium_train/img_1_transform...</td>\n",
       "      <td>0.836795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.162089</td>\n",
       "      <td>0.074007</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset/synth_eye_medium_train/img_2_original.png</td>\n",
       "      <td>Dataset/synth_eye_medium_train/img_2_transform...</td>\n",
       "      <td>1.050389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.879272</td>\n",
       "      <td>-0.117546</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset/synth_eye_medium_train/img_3_original.png</td>\n",
       "      <td>Dataset/synth_eye_medium_train/img_3_transform...</td>\n",
       "      <td>1.135652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.069543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997452</td>\n",
       "      <td>-0.048658</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset/synth_eye_medium_train/img_4_original.png</td>\n",
       "      <td>Dataset/synth_eye_medium_train/img_4_transform...</td>\n",
       "      <td>0.988166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.146850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.081306</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Dataset/synth_eye_medium_train/img_0_original.png   \n",
       "1  Dataset/synth_eye_medium_train/img_1_original.png   \n",
       "2  Dataset/synth_eye_medium_train/img_2_original.png   \n",
       "3  Dataset/synth_eye_medium_train/img_3_original.png   \n",
       "4  Dataset/synth_eye_medium_train/img_4_original.png   \n",
       "\n",
       "                                              target       M00  M01       M02  \\\n",
       "0  Dataset/synth_eye_medium_train/img_0_transform...  1.160598  0.0 -0.119816   \n",
       "1  Dataset/synth_eye_medium_train/img_1_transform...  0.836795  0.0  0.050553   \n",
       "2  Dataset/synth_eye_medium_train/img_2_transform...  1.050389  0.0  0.158718   \n",
       "3  Dataset/synth_eye_medium_train/img_3_transform...  1.135652  0.0 -0.069543   \n",
       "4  Dataset/synth_eye_medium_train/img_4_transform...  0.988166  0.0 -0.146850   \n",
       "\n",
       "   M10       M11       M12                                         image_path  \n",
       "0  0.0  1.121060 -0.031026  Dataset/Dataset-processed/15-12-2559/2011248/L...  \n",
       "1  0.0  1.162089  0.074007  Dataset/Dataset-processed/15-12-2559/2011248/L...  \n",
       "2  0.0  0.879272 -0.117546  Dataset/Dataset-processed/15-12-2559/2011248/R...  \n",
       "3  0.0  0.997452 -0.048658  Dataset/Dataset-processed/15-12-2559/2011248/R...  \n",
       "4  0.0  1.081306  0.006380  Dataset/Dataset-processed/15-12-2559/2011248/R...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>M00</th>\n",
       "      <th>M01</th>\n",
       "      <th>M02</th>\n",
       "      <th>M10</th>\n",
       "      <th>M11</th>\n",
       "      <th>M12</th>\n",
       "      <th>image_path</th>\n",
       "      <th>keypoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset/synth_eye_medium_train/img_0_original.png</td>\n",
       "      <td>Dataset/synth_eye_medium_train/img_0_transform...</td>\n",
       "      <td>1.160598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.119816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.121060</td>\n",
       "      <td>-0.031026</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "      <td>Dataset/synth_eye_medium_train/img_0_keypoints...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset/synth_eye_medium_train/img_1_original.png</td>\n",
       "      <td>Dataset/synth_eye_medium_train/img_1_transform...</td>\n",
       "      <td>0.836795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.162089</td>\n",
       "      <td>0.074007</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "      <td>Dataset/synth_eye_medium_train/img_1_keypoints...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset/synth_eye_medium_train/img_2_original.png</td>\n",
       "      <td>Dataset/synth_eye_medium_train/img_2_transform...</td>\n",
       "      <td>1.050389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.879272</td>\n",
       "      <td>-0.117546</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "      <td>Dataset/synth_eye_medium_train/img_2_keypoints...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset/synth_eye_medium_train/img_3_original.png</td>\n",
       "      <td>Dataset/synth_eye_medium_train/img_3_transform...</td>\n",
       "      <td>1.135652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.069543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997452</td>\n",
       "      <td>-0.048658</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "      <td>Dataset/synth_eye_medium_train/img_3_keypoints...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset/synth_eye_medium_train/img_4_original.png</td>\n",
       "      <td>Dataset/synth_eye_medium_train/img_4_transform...</td>\n",
       "      <td>0.988166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.146850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.081306</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "      <td>Dataset/synth_eye_medium_train/img_4_keypoints...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Dataset/synth_eye_medium_train/img_0_original.png   \n",
       "1  Dataset/synth_eye_medium_train/img_1_original.png   \n",
       "2  Dataset/synth_eye_medium_train/img_2_original.png   \n",
       "3  Dataset/synth_eye_medium_train/img_3_original.png   \n",
       "4  Dataset/synth_eye_medium_train/img_4_original.png   \n",
       "\n",
       "                                              target       M00  M01       M02  \\\n",
       "0  Dataset/synth_eye_medium_train/img_0_transform...  1.160598  0.0 -0.119816   \n",
       "1  Dataset/synth_eye_medium_train/img_1_transform...  0.836795  0.0  0.050553   \n",
       "2  Dataset/synth_eye_medium_train/img_2_transform...  1.050389  0.0  0.158718   \n",
       "3  Dataset/synth_eye_medium_train/img_3_transform...  1.135652  0.0 -0.069543   \n",
       "4  Dataset/synth_eye_medium_train/img_4_transform...  0.988166  0.0 -0.146850   \n",
       "\n",
       "   M10       M11       M12                                         image_path  \\\n",
       "0  0.0  1.121060 -0.031026  Dataset/Dataset-processed/15-12-2559/2011248/L...   \n",
       "1  0.0  1.162089  0.074007  Dataset/Dataset-processed/15-12-2559/2011248/L...   \n",
       "2  0.0  0.879272 -0.117546  Dataset/Dataset-processed/15-12-2559/2011248/R...   \n",
       "3  0.0  0.997452 -0.048658  Dataset/Dataset-processed/15-12-2559/2011248/R...   \n",
       "4  0.0  1.081306  0.006380  Dataset/Dataset-processed/15-12-2559/2011248/R...   \n",
       "\n",
       "                                           keypoints  \n",
       "0  Dataset/synth_eye_medium_train/img_0_keypoints...  \n",
       "1  Dataset/synth_eye_medium_train/img_1_keypoints...  \n",
       "2  Dataset/synth_eye_medium_train/img_2_keypoints...  \n",
       "3  Dataset/synth_eye_medium_train/img_3_keypoints...  \n",
       "4  Dataset/synth_eye_medium_train/img_4_keypoints...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add one column to the dataframe to store the path to keypoints file\n",
    "train_df['keypoints'] = train_df['source'].apply(lambda x: x.replace('_original.png', '_keypoints.csv'))\n",
    "test_df['keypoints'] = test_df['source'].apply(lambda x: x.replace('_original.png', '_keypoints.csv'))\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "train_df.to_csv('Dataset/synth_eye_medium_train.csv', index=False)\n",
    "test_df.to_csv('Dataset/synth_eye_medium_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/200 [00:00<?, ?it/s]/tmp/ipykernel_182633/2773104380.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  affine_params_true = torch.tensor(affine_params_true)\n",
      "Train:   0%|          | 1/200 [00:00<00:28,  7.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 200/200 [00:31<00:00,  6.32it/s]\n"
     ]
    }
   ],
   "source": [
    "train_bar = tqdm(train_dataset, total=len(train_dataset), desc='Train')\n",
    "for i, data in enumerate(train_bar):\n",
    "\n",
    "    # Get images and affine parameters\n",
    "    if model_params.sup:\n",
    "        source_image, target_image, affine_params_true = data\n",
    "        affine_params_true = torch.tensor(affine_params_true)\n",
    "    else:\n",
    "        source_image, target_image = data\n",
    "        affine_params_true = None\n",
    "    source_image = source_image.to(device)\n",
    "    target_image = target_image.to(device)\n",
    "\n",
    "    points1, desc1, heatmap1 = superpoint(source_image[0, 0, :, :].cpu().numpy())\n",
    "    points2, desc2, heatmap2 = superpoint(target_image[0, 0, :, :].cpu().numpy())\n",
    "\n",
    "    tracker = PointTracker(5, nn_thresh=0.7)\n",
    "    try:\n",
    "        matches = tracker.nn_match_two_way(desc1, desc2, nn_thresh=nn_thresh)\n",
    "    except:\n",
    "        print('No matches found')\n",
    "        # TODO: find a better way to do this\n",
    "        pass\n",
    "\n",
    "    matches1 = np.array(points1[:2, matches[0, :].astype(int)])\n",
    "    matches2 = np.array(points2[:2, matches[1, :].astype(int)])\n",
    "    matches1_2 = transform_points_DVF(torch.tensor(matches1), \n",
    "                        affine_params_true, target_image)\n",
    "    \n",
    "    # fig, ax = plt.subplots(1, 2)\n",
    "    # ax[0].imshow(source_image[0, 0, :, :].cpu().detach().numpy())\n",
    "    # ax[0].plot(matches1[0, :], matches1[1, :], 'r.')\n",
    "    # ax[1].imshow(target_image[0, 0, :, :].cpu().detach().numpy())\n",
    "    # ax[1].plot(matches2[0, :], matches2[1, :], 'g.')\n",
    "    # ax[1].plot(matches1_2[0, :], matches1_2[1, :], 'r.')\n",
    "    # plt.show()\n",
    "\n",
    "    # create a dataframe with the matches\n",
    "    df = pd.DataFrame({'x1': matches1[0, :], 'y1': matches1[1, :],\n",
    "                       'x2': matches2[0, :], 'y2': matches2[1, :],\n",
    "                       'x2_': matches1_2[0, :], 'y2_': matches1_2[1, :]})\n",
    "    save_name = train_df['keypoints'].iloc[i]\n",
    "    # print(save_name)\n",
    "    df.to_csv(save_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   0%|          | 0/100 [00:00<?, ?it/s]/tmp/ipykernel_182633/806415840.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  affine_params_true = torch.tensor(affine_params_true)\n",
      "Test: 100%|██████████| 100/100 [00:16<00:00,  6.17it/s]\n"
     ]
    }
   ],
   "source": [
    "test_bar = tqdm(test_dataset, total=len(test_dataset), desc='Test')\n",
    "for i, data in enumerate(test_bar):\n",
    "\n",
    "    # Get images and affine parameters\n",
    "    if model_params.sup:\n",
    "        source_image, target_image, affine_params_true = data\n",
    "        affine_params_true = torch.tensor(affine_params_true)\n",
    "    else:\n",
    "        source_image, target_image = data\n",
    "        affine_params_true = None\n",
    "    source_image = source_image.to(device)\n",
    "    target_image = target_image.to(device)\n",
    "\n",
    "    points1, desc1, heatmap1 = superpoint(source_image[0, 0, :, :].cpu().numpy())\n",
    "    points2, desc2, heatmap2 = superpoint(target_image[0, 0, :, :].cpu().numpy())\n",
    "\n",
    "    tracker = PointTracker(5, nn_thresh=0.7)\n",
    "    try:\n",
    "        matches = tracker.nn_match_two_way(desc1, desc2, nn_thresh=nn_thresh)\n",
    "    except:\n",
    "        print('No matches found')\n",
    "        # TODO: find a better way to do this\n",
    "        pass\n",
    "\n",
    "    matches1 = np.array(points1[:2, matches[0, :].astype(int)])\n",
    "    matches2 = np.array(points2[:2, matches[1, :].astype(int)])\n",
    "    matches1_2 = transform_points_DVF(torch.tensor(matches1), \n",
    "                        affine_params_true, target_image)\n",
    "    \n",
    "    # fig, ax = plt.subplots(1, 2)\n",
    "    # ax[0].imshow(source_image[0, 0, :, :].cpu().detach().numpy())\n",
    "    # ax[0].plot(matches1[0, :], matches1[1, :], 'r.')\n",
    "    # ax[1].imshow(target_image[0, 0, :, :].cpu().detach().numpy())\n",
    "    # ax[1].plot(matches2[0, :], matches2[1, :], 'g.')\n",
    "    # ax[1].plot(matches1_2[0, :], matches1_2[1, :], 'r.')\n",
    "    # plt.show()\n",
    "\n",
    "    # create a dataframe with the matches\n",
    "    df = pd.DataFrame({'x1': matches1[0, :], 'y1': matches1[1, :],\n",
    "                       'x2': matches2[0, :], 'y2': matches2[1, :],\n",
    "                       'x2_': matches1_2[0, :], 'y2_': matches1_2[1, :]})\n",
    "    save_name = test_df['keypoints'].iloc[i]\n",
    "    df.to_csv(save_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# verify that the saved keypoints are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spppt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
