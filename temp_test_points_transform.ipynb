{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DVF choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8639, 0.4092, 0.0490, 0.8620, 0.9790, 0.0482, 0.6686, 0.5067, 0.8228,\n",
      "         0.6523, 0.1760, 0.2323, 0.3223, 0.5444, 0.8475, 0.4863, 0.2013, 0.9656,\n",
      "         0.8200, 0.1296],\n",
      "        [0.6927, 0.7752, 0.8152, 0.9625, 0.0389, 0.2407, 0.5616, 0.7734, 0.8034,\n",
      "         0.8366, 0.2767, 0.0496, 0.4931, 0.2212, 0.9971, 0.8580, 0.0990, 0.9524,\n",
      "         0.0837, 0.8154]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "\n",
    "# Assuming you have tensors A and points\n",
    "A = torch.rand(2, 256, 256)\n",
    "points = torch.rand(2, 20)*256  # Replace x1, y1, x2, y2, ..., xN, yN with your actual coordinates\n",
    "\n",
    "\n",
    "# Reshape tensor points to have dimensions [2, N]\n",
    "points = points.t().long()\n",
    "\n",
    "# Use torch.gather to select values from A using indices from points\n",
    "result = A[:, points[:, 0], points[:, 1]]\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineTransform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AffineTransform, self).__init__()\n",
    "\n",
    "    def forward(self, points, matrix):\n",
    "        points = points.T\n",
    "        # Add a row of ones to the input points for the affine transformation\n",
    "        ones = torch.ones(1, points.size(1), dtype=points.dtype, device=points.device)\n",
    "        points_homogeneous = torch.cat([points, ones], dim=0)\n",
    "\n",
    "        # Apply the affine transformation\n",
    "        # print dtype of matrix and points_homogeneous\n",
    "        transformed_points = torch.mm(matrix, points_homogeneous.float())\n",
    "\n",
    "        return transformed_points[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_layer = AffineTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_param = torch.tensor([[1.0, 0.0, 0.0],\n",
    "                                [0.0, 1.0, 0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[141., 175.],\n",
       "        [196.,  75.],\n",
       "        [249.,   0.],\n",
       "        [  9.,  36.],\n",
       "        [142.,  90.],\n",
       "        [ 64.,   0.],\n",
       "        [136., 213.],\n",
       "        [ 48., 122.],\n",
       "        [ 76., 243.],\n",
       "        [148., 242.],\n",
       "        [ 53., 208.],\n",
       "        [231.,  69.],\n",
       "        [ 10., 200.],\n",
       "        [  0., 148.],\n",
       "        [ 76., 161.],\n",
       "        [151., 189.],\n",
       "        [129., 164.],\n",
       "        [ 95., 168.],\n",
       "        [201.,  10.],\n",
       "        [167.,  97.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_points = affine_layer(points, affine_param)\n",
    "transformed_points.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_displacement_field(tensor, tensor_transform, device='cpu'):\n",
    "    \"\"\"\n",
    "    Transforms a tensor using an affine transformation matrix and returns the corresponding displacement field.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): The input tensor to transform, with shape (batch_size, channels, height, width).\n",
    "        tensor_transform (torch.Tensor): The affine transformation matrix, with shape (batch_size, 2, 3).\n",
    "        device (str, optional): The device to use for the computation (default: 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The displacement field tensor, with shape (2, height, width).\n",
    "    \"\"\"\n",
    "    # function code here\n",
    "    y_size, x_size = tensor.size(2), tensor.size(3)\n",
    "    deformation_field = F.affine_grid(tensor_transform, tensor.size(), align_corners=False)\n",
    "    gy, gx = torch.meshgrid(torch.arange(y_size), torch.arange(x_size))\n",
    "    gy = gy.type(torch.FloatTensor).to(device)\n",
    "    gx = gx.type(torch.FloatTensor).to(device)\n",
    "    grid_x = (gx / (x_size - 1) - 0.5) * 2\n",
    "    grid_y = (gy / (y_size - 1) - 0.5) * 2\n",
    "    u_x = deformation_field[0, :, :, 0] - grid_x\n",
    "    u_y = deformation_field[0, :, :, 1] - grid_y\n",
    "    u_x = u_x / 2 * (x_size - 1)\n",
    "    u_y = u_y / 2 * (y_size - 1)\n",
    "    displacement_field = torch.cat((u_x.view(1, y_size, x_size), u_y.view(1, y_size, x_size)), dim=0)\n",
    "    return displacement_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_points_DVF(points, M, image):\n",
    "    # transform points using displacement field\n",
    "    # DVF.shape = (2, H, W)\n",
    "    # points.shape = (2, N)\n",
    "    displacement_field = torch.zeros(image.shape[-1], image.shape[-1])\n",
    "    DVF = transform_to_displacement_field(\n",
    "        displacement_field.view(1, 1, displacement_field.size(0), displacement_field.size(1)), \n",
    "        M.view(1, 2, 3))\n",
    "\n",
    "    # Reshape tensor points to have dimensions [2, N]\n",
    "    points = points.t().long()\n",
    "\n",
    "    # Use torch.gather to select values from A using indices from points\n",
    "    result = DVF[:, points[:, 0], points[:, 1]]\n",
    "\n",
    "    # Reshape result to have dimensions [2, N]\n",
    "    result = result.t()\n",
    "    # subtract the result from the original points\n",
    "    points = points.float()\n",
    "    result = torch.subtract(points, result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4119e+02,  1.7505e+02],\n",
       "        [ 1.9579e+02,  7.5268e+01],\n",
       "        [ 2.4850e+02,  4.7461e-01],\n",
       "        [ 8.6426e+00,  3.5537e+01],\n",
       "        [ 1.4185e+02,  9.0057e+01],\n",
       "        [ 6.3502e+01, -2.4805e-01],\n",
       "        [ 1.3633e+02,  2.1303e+02],\n",
       "        [ 4.7979e+01,  1.2169e+02],\n",
       "        [ 7.6451e+01,  2.4280e+02],\n",
       "        [ 1.4845e+02,  2.4208e+02],\n",
       "        [ 5.3314e+01,  2.0771e+02],\n",
       "        [ 2.3077e+02,  6.9404e+01],\n",
       "        [ 1.0283e+01,  1.9954e+02],\n",
       "        [ 8.0092e-02,  1.4750e+02],\n",
       "        [ 7.6131e+01,  1.6080e+02],\n",
       "        [ 1.5124e+02,  1.8909e+02],\n",
       "        [ 1.2914e+02,  1.6401e+02],\n",
       "        [ 9.5158e+01,  1.6787e+02],\n",
       "        [ 2.0054e+02,  1.0287e+01],\n",
       "        [ 1.6688e+02,  9.7154e+01]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_points = transform_points_DVF(points.T, affine_param, A)\n",
    "transformed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spppt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
